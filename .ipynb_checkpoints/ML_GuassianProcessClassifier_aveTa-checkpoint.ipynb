{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed csv:  data_20190303_1035_0.csv\n",
      "['data_20190301_1035_2.csv', 'data_20190303_1035_1.csv', 'data_20190309_1008_3.csv', 'data_20190309_1334_3.csv', 'data_20190309_1336_3.csv', 'data_20190309_1342_2.csv', 'data_20190309_1358_2.csv', 'data_20190309_1405_2.csv', 'data_20190309_1409_1.csv', 'data_20190309_1411_1.csv', 'data_20190309_1413_1.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# file_dir = os.getcwd()\n",
    "# raw_data_dir = os.path.join(file_dir, '/raw_data')\n",
    "file_list = []\n",
    "\n",
    "for root, dirs, files in os.walk('./raw_data'):\n",
    "    for file in files:\n",
    "        if os.path.splitext(file)[1] == '.csv':\n",
    "        # 排除掉readme.md等非csv文件\n",
    "            file_list.append(file)\n",
    "\n",
    "# print(file_list)  \n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for index, csv in enumerate(file_list):\n",
    "    \n",
    "    df_temp = pd.read_csv('./raw_data/'+csv)\n",
    "    if int(csv[-5]) == 0:\n",
    "        file_list[index] = csv[:-5] + '1' +csv[-4:]\n",
    "        print('changed csv: ', csv)\n",
    "    target_column = pd.DataFrame(np.array([int(file_list[index][-5])]*df_temp.shape[0]))\n",
    "    # 构造target列，注意要使用二维的array [[1],[1]]这样是列 [[1,1]]这样是行\n",
    "    df_temp = pd.concat([df_temp, target_column], axis=1, ignore_index=True)\n",
    "    # 连接样本和target列\n",
    "    df = pd.concat([df, df_temp], ignore_index=True)\n",
    "    # 连接所有样本\n",
    "    \n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.62949</td>\n",
       "      <td>23.34601</td>\n",
       "      <td>22.84607</td>\n",
       "      <td>24.27225</td>\n",
       "      <td>24.22751</td>\n",
       "      <td>24.99457</td>\n",
       "      <td>27.39221</td>\n",
       "      <td>26.94012</td>\n",
       "      <td>27.34689</td>\n",
       "      <td>27.80975</td>\n",
       "      <td>...</td>\n",
       "      <td>25.27432</td>\n",
       "      <td>22.86929</td>\n",
       "      <td>22.75967</td>\n",
       "      <td>22.38684</td>\n",
       "      <td>22.88013</td>\n",
       "      <td>22.94119</td>\n",
       "      <td>22.99555</td>\n",
       "      <td>22.63037</td>\n",
       "      <td>23.33066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.16067</td>\n",
       "      <td>23.59763</td>\n",
       "      <td>25.04761</td>\n",
       "      <td>24.74619</td>\n",
       "      <td>27.40509</td>\n",
       "      <td>27.20163</td>\n",
       "      <td>28.14008</td>\n",
       "      <td>27.87192</td>\n",
       "      <td>28.14847</td>\n",
       "      <td>27.80102</td>\n",
       "      <td>...</td>\n",
       "      <td>23.29489</td>\n",
       "      <td>22.53711</td>\n",
       "      <td>22.20065</td>\n",
       "      <td>22.37799</td>\n",
       "      <td>22.64114</td>\n",
       "      <td>21.91843</td>\n",
       "      <td>22.99634</td>\n",
       "      <td>23.05240</td>\n",
       "      <td>22.60111</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.03558</td>\n",
       "      <td>24.24997</td>\n",
       "      <td>23.59360</td>\n",
       "      <td>24.87021</td>\n",
       "      <td>25.99951</td>\n",
       "      <td>27.53504</td>\n",
       "      <td>27.61453</td>\n",
       "      <td>28.60287</td>\n",
       "      <td>27.45639</td>\n",
       "      <td>27.70782</td>\n",
       "      <td>...</td>\n",
       "      <td>22.45697</td>\n",
       "      <td>21.56348</td>\n",
       "      <td>22.20950</td>\n",
       "      <td>22.61514</td>\n",
       "      <td>22.40997</td>\n",
       "      <td>22.42819</td>\n",
       "      <td>22.61395</td>\n",
       "      <td>23.05298</td>\n",
       "      <td>23.48731</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.25803</td>\n",
       "      <td>23.60641</td>\n",
       "      <td>22.50025</td>\n",
       "      <td>24.63440</td>\n",
       "      <td>23.02280</td>\n",
       "      <td>26.32965</td>\n",
       "      <td>24.39380</td>\n",
       "      <td>27.77655</td>\n",
       "      <td>26.36633</td>\n",
       "      <td>27.61267</td>\n",
       "      <td>...</td>\n",
       "      <td>23.10901</td>\n",
       "      <td>21.89667</td>\n",
       "      <td>22.56369</td>\n",
       "      <td>22.38712</td>\n",
       "      <td>22.90918</td>\n",
       "      <td>22.18204</td>\n",
       "      <td>22.10751</td>\n",
       "      <td>22.77466</td>\n",
       "      <td>23.50760</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.11905</td>\n",
       "      <td>23.36346</td>\n",
       "      <td>22.37064</td>\n",
       "      <td>22.95017</td>\n",
       "      <td>22.00073</td>\n",
       "      <td>22.74686</td>\n",
       "      <td>22.73328</td>\n",
       "      <td>22.88919</td>\n",
       "      <td>22.98193</td>\n",
       "      <td>23.40122</td>\n",
       "      <td>...</td>\n",
       "      <td>23.62778</td>\n",
       "      <td>22.02560</td>\n",
       "      <td>21.54199</td>\n",
       "      <td>22.05508</td>\n",
       "      <td>22.78049</td>\n",
       "      <td>21.82272</td>\n",
       "      <td>22.62360</td>\n",
       "      <td>22.51157</td>\n",
       "      <td>23.20691</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.24774</td>\n",
       "      <td>22.82923</td>\n",
       "      <td>22.61456</td>\n",
       "      <td>22.57074</td>\n",
       "      <td>23.90958</td>\n",
       "      <td>23.42151</td>\n",
       "      <td>29.41101</td>\n",
       "      <td>25.57358</td>\n",
       "      <td>31.09058</td>\n",
       "      <td>27.32391</td>\n",
       "      <td>...</td>\n",
       "      <td>27.53855</td>\n",
       "      <td>22.44513</td>\n",
       "      <td>26.72360</td>\n",
       "      <td>23.09903</td>\n",
       "      <td>27.47080</td>\n",
       "      <td>23.32593</td>\n",
       "      <td>26.35037</td>\n",
       "      <td>23.63992</td>\n",
       "      <td>25.92902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.52435</td>\n",
       "      <td>23.08780</td>\n",
       "      <td>22.99613</td>\n",
       "      <td>23.42499</td>\n",
       "      <td>27.74887</td>\n",
       "      <td>27.32492</td>\n",
       "      <td>32.70804</td>\n",
       "      <td>31.86749</td>\n",
       "      <td>32.91443</td>\n",
       "      <td>31.11096</td>\n",
       "      <td>...</td>\n",
       "      <td>27.65057</td>\n",
       "      <td>26.46704</td>\n",
       "      <td>26.62717</td>\n",
       "      <td>28.45911</td>\n",
       "      <td>28.85034</td>\n",
       "      <td>27.50784</td>\n",
       "      <td>26.86649</td>\n",
       "      <td>26.02933</td>\n",
       "      <td>26.92896</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.37411</td>\n",
       "      <td>22.70657</td>\n",
       "      <td>23.83859</td>\n",
       "      <td>25.60977</td>\n",
       "      <td>30.59570</td>\n",
       "      <td>31.41663</td>\n",
       "      <td>33.40170</td>\n",
       "      <td>34.25433</td>\n",
       "      <td>34.12695</td>\n",
       "      <td>33.94504</td>\n",
       "      <td>...</td>\n",
       "      <td>26.92328</td>\n",
       "      <td>26.37424</td>\n",
       "      <td>27.03885</td>\n",
       "      <td>27.01385</td>\n",
       "      <td>26.07596</td>\n",
       "      <td>25.69312</td>\n",
       "      <td>26.34161</td>\n",
       "      <td>25.90204</td>\n",
       "      <td>25.91846</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.86481</td>\n",
       "      <td>23.21832</td>\n",
       "      <td>25.19602</td>\n",
       "      <td>27.96146</td>\n",
       "      <td>31.86359</td>\n",
       "      <td>33.18375</td>\n",
       "      <td>32.81717</td>\n",
       "      <td>33.36041</td>\n",
       "      <td>33.39514</td>\n",
       "      <td>34.12235</td>\n",
       "      <td>...</td>\n",
       "      <td>26.64026</td>\n",
       "      <td>25.84201</td>\n",
       "      <td>26.19956</td>\n",
       "      <td>26.21033</td>\n",
       "      <td>26.44818</td>\n",
       "      <td>25.68188</td>\n",
       "      <td>25.34921</td>\n",
       "      <td>25.75110</td>\n",
       "      <td>26.08591</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.52863</td>\n",
       "      <td>23.10373</td>\n",
       "      <td>25.43658</td>\n",
       "      <td>28.09415</td>\n",
       "      <td>31.44864</td>\n",
       "      <td>32.99234</td>\n",
       "      <td>32.91727</td>\n",
       "      <td>33.77081</td>\n",
       "      <td>33.67676</td>\n",
       "      <td>33.58032</td>\n",
       "      <td>...</td>\n",
       "      <td>27.35138</td>\n",
       "      <td>25.64829</td>\n",
       "      <td>26.19898</td>\n",
       "      <td>26.56589</td>\n",
       "      <td>26.56338</td>\n",
       "      <td>26.18738</td>\n",
       "      <td>25.98495</td>\n",
       "      <td>26.04471</td>\n",
       "      <td>26.22647</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.87976</td>\n",
       "      <td>23.23874</td>\n",
       "      <td>24.48318</td>\n",
       "      <td>26.80637</td>\n",
       "      <td>31.04550</td>\n",
       "      <td>32.57886</td>\n",
       "      <td>33.03000</td>\n",
       "      <td>32.98303</td>\n",
       "      <td>33.40576</td>\n",
       "      <td>33.76898</td>\n",
       "      <td>...</td>\n",
       "      <td>26.75708</td>\n",
       "      <td>25.54871</td>\n",
       "      <td>26.32297</td>\n",
       "      <td>26.23163</td>\n",
       "      <td>25.99960</td>\n",
       "      <td>25.33429</td>\n",
       "      <td>25.74826</td>\n",
       "      <td>25.63361</td>\n",
       "      <td>26.10413</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.01593</td>\n",
       "      <td>23.12048</td>\n",
       "      <td>23.14093</td>\n",
       "      <td>26.81812</td>\n",
       "      <td>29.89594</td>\n",
       "      <td>33.31625</td>\n",
       "      <td>33.93530</td>\n",
       "      <td>33.38922</td>\n",
       "      <td>34.06494</td>\n",
       "      <td>33.77905</td>\n",
       "      <td>...</td>\n",
       "      <td>26.96378</td>\n",
       "      <td>26.81216</td>\n",
       "      <td>26.32636</td>\n",
       "      <td>25.90359</td>\n",
       "      <td>26.46802</td>\n",
       "      <td>25.47122</td>\n",
       "      <td>26.25971</td>\n",
       "      <td>25.50830</td>\n",
       "      <td>26.53262</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21.73358</td>\n",
       "      <td>22.46457</td>\n",
       "      <td>21.51373</td>\n",
       "      <td>23.94440</td>\n",
       "      <td>24.70673</td>\n",
       "      <td>29.95139</td>\n",
       "      <td>31.09051</td>\n",
       "      <td>33.68460</td>\n",
       "      <td>33.68460</td>\n",
       "      <td>34.42801</td>\n",
       "      <td>...</td>\n",
       "      <td>27.35434</td>\n",
       "      <td>27.01865</td>\n",
       "      <td>26.09277</td>\n",
       "      <td>27.37488</td>\n",
       "      <td>28.06040</td>\n",
       "      <td>26.69430</td>\n",
       "      <td>27.12216</td>\n",
       "      <td>25.64749</td>\n",
       "      <td>26.79062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.60510</td>\n",
       "      <td>22.83392</td>\n",
       "      <td>22.02408</td>\n",
       "      <td>22.08896</td>\n",
       "      <td>22.82910</td>\n",
       "      <td>25.91690</td>\n",
       "      <td>28.29785</td>\n",
       "      <td>31.69977</td>\n",
       "      <td>32.47879</td>\n",
       "      <td>33.60327</td>\n",
       "      <td>...</td>\n",
       "      <td>27.99423</td>\n",
       "      <td>26.50235</td>\n",
       "      <td>26.12140</td>\n",
       "      <td>27.47952</td>\n",
       "      <td>27.39694</td>\n",
       "      <td>26.55670</td>\n",
       "      <td>26.38022</td>\n",
       "      <td>25.75241</td>\n",
       "      <td>24.95172</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21.35684</td>\n",
       "      <td>22.45941</td>\n",
       "      <td>22.04224</td>\n",
       "      <td>22.60257</td>\n",
       "      <td>23.18390</td>\n",
       "      <td>24.70514</td>\n",
       "      <td>27.57144</td>\n",
       "      <td>30.19763</td>\n",
       "      <td>30.57199</td>\n",
       "      <td>32.67972</td>\n",
       "      <td>...</td>\n",
       "      <td>25.36157</td>\n",
       "      <td>25.26813</td>\n",
       "      <td>22.84131</td>\n",
       "      <td>25.91684</td>\n",
       "      <td>23.55621</td>\n",
       "      <td>25.47690</td>\n",
       "      <td>23.19327</td>\n",
       "      <td>23.80368</td>\n",
       "      <td>23.24545</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21.90445</td>\n",
       "      <td>22.48276</td>\n",
       "      <td>21.67545</td>\n",
       "      <td>22.24854</td>\n",
       "      <td>22.84360</td>\n",
       "      <td>23.24094</td>\n",
       "      <td>26.71466</td>\n",
       "      <td>28.03738</td>\n",
       "      <td>29.58966</td>\n",
       "      <td>29.23184</td>\n",
       "      <td>...</td>\n",
       "      <td>22.72952</td>\n",
       "      <td>21.62570</td>\n",
       "      <td>21.47946</td>\n",
       "      <td>22.56009</td>\n",
       "      <td>21.74496</td>\n",
       "      <td>21.72848</td>\n",
       "      <td>21.75232</td>\n",
       "      <td>22.83026</td>\n",
       "      <td>23.25714</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22.17194</td>\n",
       "      <td>23.01645</td>\n",
       "      <td>21.67660</td>\n",
       "      <td>22.62653</td>\n",
       "      <td>22.95731</td>\n",
       "      <td>23.81754</td>\n",
       "      <td>25.31375</td>\n",
       "      <td>27.73398</td>\n",
       "      <td>29.49326</td>\n",
       "      <td>29.33792</td>\n",
       "      <td>...</td>\n",
       "      <td>22.94269</td>\n",
       "      <td>21.30749</td>\n",
       "      <td>21.36768</td>\n",
       "      <td>21.26559</td>\n",
       "      <td>22.47235</td>\n",
       "      <td>22.37424</td>\n",
       "      <td>22.54459</td>\n",
       "      <td>22.55234</td>\n",
       "      <td>22.67609</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.24469</td>\n",
       "      <td>22.75302</td>\n",
       "      <td>21.05750</td>\n",
       "      <td>22.99377</td>\n",
       "      <td>22.73932</td>\n",
       "      <td>23.70319</td>\n",
       "      <td>25.64670</td>\n",
       "      <td>27.62906</td>\n",
       "      <td>29.50140</td>\n",
       "      <td>29.72510</td>\n",
       "      <td>...</td>\n",
       "      <td>22.94949</td>\n",
       "      <td>21.52469</td>\n",
       "      <td>21.37412</td>\n",
       "      <td>21.97769</td>\n",
       "      <td>22.35831</td>\n",
       "      <td>21.48108</td>\n",
       "      <td>22.02469</td>\n",
       "      <td>22.55109</td>\n",
       "      <td>22.09515</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22.04459</td>\n",
       "      <td>22.74832</td>\n",
       "      <td>20.81064</td>\n",
       "      <td>22.25830</td>\n",
       "      <td>23.09250</td>\n",
       "      <td>24.50583</td>\n",
       "      <td>25.44620</td>\n",
       "      <td>27.54132</td>\n",
       "      <td>29.32816</td>\n",
       "      <td>29.74796</td>\n",
       "      <td>...</td>\n",
       "      <td>22.65936</td>\n",
       "      <td>21.43625</td>\n",
       "      <td>21.28198</td>\n",
       "      <td>21.87119</td>\n",
       "      <td>21.76950</td>\n",
       "      <td>21.86862</td>\n",
       "      <td>22.42493</td>\n",
       "      <td>21.81622</td>\n",
       "      <td>22.38440</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>22.05759</td>\n",
       "      <td>22.23212</td>\n",
       "      <td>21.82614</td>\n",
       "      <td>22.26892</td>\n",
       "      <td>22.87967</td>\n",
       "      <td>24.17767</td>\n",
       "      <td>25.78269</td>\n",
       "      <td>28.07236</td>\n",
       "      <td>29.53482</td>\n",
       "      <td>29.75775</td>\n",
       "      <td>...</td>\n",
       "      <td>23.09647</td>\n",
       "      <td>21.77469</td>\n",
       "      <td>21.52301</td>\n",
       "      <td>21.40729</td>\n",
       "      <td>21.90558</td>\n",
       "      <td>22.26239</td>\n",
       "      <td>21.64844</td>\n",
       "      <td>22.11862</td>\n",
       "      <td>23.13190</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.65164</td>\n",
       "      <td>22.50772</td>\n",
       "      <td>21.44568</td>\n",
       "      <td>22.40412</td>\n",
       "      <td>22.76193</td>\n",
       "      <td>23.62250</td>\n",
       "      <td>24.90985</td>\n",
       "      <td>28.49780</td>\n",
       "      <td>29.13989</td>\n",
       "      <td>29.57425</td>\n",
       "      <td>...</td>\n",
       "      <td>21.70679</td>\n",
       "      <td>21.56928</td>\n",
       "      <td>21.40186</td>\n",
       "      <td>21.77722</td>\n",
       "      <td>22.38107</td>\n",
       "      <td>21.25391</td>\n",
       "      <td>21.63956</td>\n",
       "      <td>22.42136</td>\n",
       "      <td>22.39053</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.79492</td>\n",
       "      <td>22.63193</td>\n",
       "      <td>21.58054</td>\n",
       "      <td>22.39667</td>\n",
       "      <td>22.77148</td>\n",
       "      <td>23.38864</td>\n",
       "      <td>24.59131</td>\n",
       "      <td>26.92798</td>\n",
       "      <td>28.16141</td>\n",
       "      <td>28.79175</td>\n",
       "      <td>...</td>\n",
       "      <td>21.50253</td>\n",
       "      <td>21.45084</td>\n",
       "      <td>21.86462</td>\n",
       "      <td>21.40936</td>\n",
       "      <td>22.51175</td>\n",
       "      <td>22.01025</td>\n",
       "      <td>22.70367</td>\n",
       "      <td>21.97470</td>\n",
       "      <td>22.98636</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.07364</td>\n",
       "      <td>22.11783</td>\n",
       "      <td>21.84213</td>\n",
       "      <td>22.16305</td>\n",
       "      <td>23.34537</td>\n",
       "      <td>23.40137</td>\n",
       "      <td>24.60248</td>\n",
       "      <td>26.09586</td>\n",
       "      <td>27.67517</td>\n",
       "      <td>27.72376</td>\n",
       "      <td>...</td>\n",
       "      <td>21.94357</td>\n",
       "      <td>21.35645</td>\n",
       "      <td>21.53830</td>\n",
       "      <td>21.42532</td>\n",
       "      <td>22.40463</td>\n",
       "      <td>21.64328</td>\n",
       "      <td>22.32340</td>\n",
       "      <td>21.99188</td>\n",
       "      <td>22.56226</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.07947</td>\n",
       "      <td>21.99545</td>\n",
       "      <td>22.09671</td>\n",
       "      <td>22.29648</td>\n",
       "      <td>21.88205</td>\n",
       "      <td>23.06897</td>\n",
       "      <td>23.39655</td>\n",
       "      <td>24.71884</td>\n",
       "      <td>24.74893</td>\n",
       "      <td>26.84152</td>\n",
       "      <td>...</td>\n",
       "      <td>22.16425</td>\n",
       "      <td>21.47592</td>\n",
       "      <td>21.88525</td>\n",
       "      <td>22.02985</td>\n",
       "      <td>22.53336</td>\n",
       "      <td>21.90909</td>\n",
       "      <td>22.46350</td>\n",
       "      <td>22.29205</td>\n",
       "      <td>22.57217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21.40631</td>\n",
       "      <td>22.39935</td>\n",
       "      <td>21.59253</td>\n",
       "      <td>22.30396</td>\n",
       "      <td>21.64908</td>\n",
       "      <td>22.61768</td>\n",
       "      <td>22.39102</td>\n",
       "      <td>23.21118</td>\n",
       "      <td>23.09219</td>\n",
       "      <td>24.83814</td>\n",
       "      <td>...</td>\n",
       "      <td>22.05051</td>\n",
       "      <td>21.59433</td>\n",
       "      <td>21.76480</td>\n",
       "      <td>22.51328</td>\n",
       "      <td>22.28427</td>\n",
       "      <td>21.91980</td>\n",
       "      <td>22.45529</td>\n",
       "      <td>22.44907</td>\n",
       "      <td>22.12213</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21.41837</td>\n",
       "      <td>22.12738</td>\n",
       "      <td>21.10294</td>\n",
       "      <td>21.92493</td>\n",
       "      <td>21.20355</td>\n",
       "      <td>22.15060</td>\n",
       "      <td>22.62564</td>\n",
       "      <td>22.32889</td>\n",
       "      <td>22.68591</td>\n",
       "      <td>23.50516</td>\n",
       "      <td>...</td>\n",
       "      <td>22.06314</td>\n",
       "      <td>21.14789</td>\n",
       "      <td>21.55130</td>\n",
       "      <td>22.14853</td>\n",
       "      <td>22.17661</td>\n",
       "      <td>21.39792</td>\n",
       "      <td>22.20551</td>\n",
       "      <td>21.56708</td>\n",
       "      <td>22.72351</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21.70432</td>\n",
       "      <td>21.87775</td>\n",
       "      <td>21.99606</td>\n",
       "      <td>22.31107</td>\n",
       "      <td>21.56372</td>\n",
       "      <td>22.39517</td>\n",
       "      <td>22.41864</td>\n",
       "      <td>22.78177</td>\n",
       "      <td>23.43085</td>\n",
       "      <td>24.13342</td>\n",
       "      <td>...</td>\n",
       "      <td>21.86972</td>\n",
       "      <td>21.38397</td>\n",
       "      <td>21.79846</td>\n",
       "      <td>21.45471</td>\n",
       "      <td>22.07779</td>\n",
       "      <td>21.67273</td>\n",
       "      <td>22.22833</td>\n",
       "      <td>21.87860</td>\n",
       "      <td>22.89502</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21.29791</td>\n",
       "      <td>21.36118</td>\n",
       "      <td>20.86432</td>\n",
       "      <td>21.95465</td>\n",
       "      <td>22.12842</td>\n",
       "      <td>22.52411</td>\n",
       "      <td>22.41464</td>\n",
       "      <td>22.57669</td>\n",
       "      <td>23.42728</td>\n",
       "      <td>23.32672</td>\n",
       "      <td>...</td>\n",
       "      <td>21.75671</td>\n",
       "      <td>20.96216</td>\n",
       "      <td>22.01792</td>\n",
       "      <td>21.35269</td>\n",
       "      <td>22.07098</td>\n",
       "      <td>21.17746</td>\n",
       "      <td>21.69306</td>\n",
       "      <td>21.60654</td>\n",
       "      <td>22.15378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21.31738</td>\n",
       "      <td>21.88889</td>\n",
       "      <td>22.00983</td>\n",
       "      <td>22.44550</td>\n",
       "      <td>22.03265</td>\n",
       "      <td>22.97925</td>\n",
       "      <td>22.54337</td>\n",
       "      <td>23.22916</td>\n",
       "      <td>23.96118</td>\n",
       "      <td>25.76508</td>\n",
       "      <td>...</td>\n",
       "      <td>22.09863</td>\n",
       "      <td>21.61487</td>\n",
       "      <td>21.58798</td>\n",
       "      <td>21.70621</td>\n",
       "      <td>22.69760</td>\n",
       "      <td>21.68622</td>\n",
       "      <td>21.98172</td>\n",
       "      <td>21.60248</td>\n",
       "      <td>22.76752</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21.43283</td>\n",
       "      <td>22.29840</td>\n",
       "      <td>21.99240</td>\n",
       "      <td>22.21118</td>\n",
       "      <td>22.69519</td>\n",
       "      <td>22.87704</td>\n",
       "      <td>25.38934</td>\n",
       "      <td>23.35007</td>\n",
       "      <td>25.99094</td>\n",
       "      <td>24.46143</td>\n",
       "      <td>...</td>\n",
       "      <td>21.11368</td>\n",
       "      <td>21.19037</td>\n",
       "      <td>20.99921</td>\n",
       "      <td>21.59988</td>\n",
       "      <td>21.95111</td>\n",
       "      <td>21.44302</td>\n",
       "      <td>21.56189</td>\n",
       "      <td>22.34039</td>\n",
       "      <td>21.86041</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>25.11514</td>\n",
       "      <td>25.41595</td>\n",
       "      <td>25.12030</td>\n",
       "      <td>25.51492</td>\n",
       "      <td>24.93973</td>\n",
       "      <td>25.44421</td>\n",
       "      <td>25.23868</td>\n",
       "      <td>25.24881</td>\n",
       "      <td>24.80594</td>\n",
       "      <td>25.21539</td>\n",
       "      <td>...</td>\n",
       "      <td>25.92810</td>\n",
       "      <td>23.80734</td>\n",
       "      <td>23.87439</td>\n",
       "      <td>24.45477</td>\n",
       "      <td>24.24927</td>\n",
       "      <td>24.41800</td>\n",
       "      <td>24.51227</td>\n",
       "      <td>23.93637</td>\n",
       "      <td>24.35904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>24.71115</td>\n",
       "      <td>25.90851</td>\n",
       "      <td>24.74731</td>\n",
       "      <td>24.93405</td>\n",
       "      <td>24.71451</td>\n",
       "      <td>25.34497</td>\n",
       "      <td>25.01752</td>\n",
       "      <td>24.95053</td>\n",
       "      <td>24.90207</td>\n",
       "      <td>25.43063</td>\n",
       "      <td>...</td>\n",
       "      <td>26.22876</td>\n",
       "      <td>23.93301</td>\n",
       "      <td>23.65390</td>\n",
       "      <td>24.01929</td>\n",
       "      <td>24.00851</td>\n",
       "      <td>23.69748</td>\n",
       "      <td>24.49203</td>\n",
       "      <td>24.20822</td>\n",
       "      <td>24.74823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>25.11624</td>\n",
       "      <td>25.02682</td>\n",
       "      <td>24.17734</td>\n",
       "      <td>25.26712</td>\n",
       "      <td>24.94064</td>\n",
       "      <td>24.77573</td>\n",
       "      <td>25.02786</td>\n",
       "      <td>25.23380</td>\n",
       "      <td>25.40241</td>\n",
       "      <td>25.10181</td>\n",
       "      <td>...</td>\n",
       "      <td>26.12918</td>\n",
       "      <td>23.68912</td>\n",
       "      <td>24.19858</td>\n",
       "      <td>23.65027</td>\n",
       "      <td>23.78937</td>\n",
       "      <td>23.43134</td>\n",
       "      <td>24.01227</td>\n",
       "      <td>24.47513</td>\n",
       "      <td>24.92017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>24.85785</td>\n",
       "      <td>25.16965</td>\n",
       "      <td>25.23157</td>\n",
       "      <td>24.93448</td>\n",
       "      <td>24.93356</td>\n",
       "      <td>25.22943</td>\n",
       "      <td>24.91470</td>\n",
       "      <td>24.62653</td>\n",
       "      <td>25.29599</td>\n",
       "      <td>25.02109</td>\n",
       "      <td>...</td>\n",
       "      <td>25.82364</td>\n",
       "      <td>23.70734</td>\n",
       "      <td>23.97864</td>\n",
       "      <td>23.55521</td>\n",
       "      <td>24.47638</td>\n",
       "      <td>23.57199</td>\n",
       "      <td>24.25906</td>\n",
       "      <td>23.24814</td>\n",
       "      <td>24.49747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>24.34683</td>\n",
       "      <td>25.04321</td>\n",
       "      <td>25.10791</td>\n",
       "      <td>25.39975</td>\n",
       "      <td>24.38895</td>\n",
       "      <td>25.11804</td>\n",
       "      <td>25.33124</td>\n",
       "      <td>25.04117</td>\n",
       "      <td>25.09100</td>\n",
       "      <td>25.21469</td>\n",
       "      <td>...</td>\n",
       "      <td>25.31635</td>\n",
       "      <td>23.29224</td>\n",
       "      <td>23.43356</td>\n",
       "      <td>23.10364</td>\n",
       "      <td>24.58539</td>\n",
       "      <td>23.20853</td>\n",
       "      <td>24.25348</td>\n",
       "      <td>24.49905</td>\n",
       "      <td>24.91095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>24.71558</td>\n",
       "      <td>25.03067</td>\n",
       "      <td>24.86289</td>\n",
       "      <td>24.68625</td>\n",
       "      <td>25.02460</td>\n",
       "      <td>24.99725</td>\n",
       "      <td>25.11017</td>\n",
       "      <td>25.23709</td>\n",
       "      <td>25.57648</td>\n",
       "      <td>24.90799</td>\n",
       "      <td>...</td>\n",
       "      <td>25.30637</td>\n",
       "      <td>22.86005</td>\n",
       "      <td>23.20740</td>\n",
       "      <td>23.20190</td>\n",
       "      <td>24.34534</td>\n",
       "      <td>23.43741</td>\n",
       "      <td>24.61899</td>\n",
       "      <td>23.93054</td>\n",
       "      <td>24.90018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>25.84372</td>\n",
       "      <td>25.14862</td>\n",
       "      <td>24.15433</td>\n",
       "      <td>25.14734</td>\n",
       "      <td>25.02460</td>\n",
       "      <td>24.55344</td>\n",
       "      <td>25.32153</td>\n",
       "      <td>24.91812</td>\n",
       "      <td>25.27969</td>\n",
       "      <td>24.70364</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40573</td>\n",
       "      <td>23.89502</td>\n",
       "      <td>24.28470</td>\n",
       "      <td>23.30978</td>\n",
       "      <td>24.68988</td>\n",
       "      <td>23.30917</td>\n",
       "      <td>24.36865</td>\n",
       "      <td>24.06320</td>\n",
       "      <td>24.76084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>24.83258</td>\n",
       "      <td>25.51459</td>\n",
       "      <td>24.97784</td>\n",
       "      <td>25.26343</td>\n",
       "      <td>24.70935</td>\n",
       "      <td>25.32306</td>\n",
       "      <td>25.11783</td>\n",
       "      <td>25.13705</td>\n",
       "      <td>25.19440</td>\n",
       "      <td>25.21219</td>\n",
       "      <td>...</td>\n",
       "      <td>26.72226</td>\n",
       "      <td>23.91257</td>\n",
       "      <td>24.29721</td>\n",
       "      <td>23.77390</td>\n",
       "      <td>25.38339</td>\n",
       "      <td>23.92139</td>\n",
       "      <td>24.99075</td>\n",
       "      <td>24.60321</td>\n",
       "      <td>25.16617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>25.59906</td>\n",
       "      <td>24.77402</td>\n",
       "      <td>24.75009</td>\n",
       "      <td>25.49728</td>\n",
       "      <td>24.49210</td>\n",
       "      <td>24.44424</td>\n",
       "      <td>24.79785</td>\n",
       "      <td>24.91846</td>\n",
       "      <td>25.58246</td>\n",
       "      <td>24.90109</td>\n",
       "      <td>...</td>\n",
       "      <td>26.70703</td>\n",
       "      <td>24.10275</td>\n",
       "      <td>24.07181</td>\n",
       "      <td>23.31064</td>\n",
       "      <td>24.23129</td>\n",
       "      <td>23.43219</td>\n",
       "      <td>24.49442</td>\n",
       "      <td>24.34012</td>\n",
       "      <td>24.76004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>24.71439</td>\n",
       "      <td>24.90176</td>\n",
       "      <td>24.38992</td>\n",
       "      <td>25.03357</td>\n",
       "      <td>24.70139</td>\n",
       "      <td>25.53751</td>\n",
       "      <td>24.68530</td>\n",
       "      <td>24.81754</td>\n",
       "      <td>25.47693</td>\n",
       "      <td>25.39642</td>\n",
       "      <td>...</td>\n",
       "      <td>26.00565</td>\n",
       "      <td>24.41367</td>\n",
       "      <td>23.85294</td>\n",
       "      <td>23.53680</td>\n",
       "      <td>24.68759</td>\n",
       "      <td>23.43134</td>\n",
       "      <td>24.99097</td>\n",
       "      <td>23.78488</td>\n",
       "      <td>24.33862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>24.84036</td>\n",
       "      <td>25.39636</td>\n",
       "      <td>25.68259</td>\n",
       "      <td>25.14584</td>\n",
       "      <td>25.02365</td>\n",
       "      <td>25.31519</td>\n",
       "      <td>25.42627</td>\n",
       "      <td>24.91678</td>\n",
       "      <td>25.87173</td>\n",
       "      <td>25.39093</td>\n",
       "      <td>...</td>\n",
       "      <td>25.80582</td>\n",
       "      <td>23.89313</td>\n",
       "      <td>23.85294</td>\n",
       "      <td>23.98749</td>\n",
       "      <td>25.03104</td>\n",
       "      <td>23.79468</td>\n",
       "      <td>24.61649</td>\n",
       "      <td>23.78387</td>\n",
       "      <td>25.31418</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>25.20926</td>\n",
       "      <td>25.39636</td>\n",
       "      <td>24.26355</td>\n",
       "      <td>25.37903</td>\n",
       "      <td>24.69333</td>\n",
       "      <td>24.98883</td>\n",
       "      <td>24.88944</td>\n",
       "      <td>25.53973</td>\n",
       "      <td>24.97314</td>\n",
       "      <td>25.58682</td>\n",
       "      <td>...</td>\n",
       "      <td>26.59491</td>\n",
       "      <td>23.68567</td>\n",
       "      <td>24.16757</td>\n",
       "      <td>24.10040</td>\n",
       "      <td>24.56506</td>\n",
       "      <td>23.06201</td>\n",
       "      <td>24.23306</td>\n",
       "      <td>24.47391</td>\n",
       "      <td>24.47092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>25.21127</td>\n",
       "      <td>25.63919</td>\n",
       "      <td>24.73779</td>\n",
       "      <td>25.14011</td>\n",
       "      <td>24.58737</td>\n",
       "      <td>24.87369</td>\n",
       "      <td>25.10281</td>\n",
       "      <td>24.80655</td>\n",
       "      <td>25.37137</td>\n",
       "      <td>25.38461</td>\n",
       "      <td>...</td>\n",
       "      <td>26.19931</td>\n",
       "      <td>24.30212</td>\n",
       "      <td>24.59808</td>\n",
       "      <td>23.98376</td>\n",
       "      <td>24.45261</td>\n",
       "      <td>23.91242</td>\n",
       "      <td>24.23566</td>\n",
       "      <td>23.64264</td>\n",
       "      <td>24.19397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>24.83337</td>\n",
       "      <td>25.01309</td>\n",
       "      <td>24.97241</td>\n",
       "      <td>25.83484</td>\n",
       "      <td>24.37103</td>\n",
       "      <td>25.19751</td>\n",
       "      <td>25.62964</td>\n",
       "      <td>25.21976</td>\n",
       "      <td>24.97394</td>\n",
       "      <td>25.38199</td>\n",
       "      <td>...</td>\n",
       "      <td>26.29816</td>\n",
       "      <td>23.88367</td>\n",
       "      <td>24.06198</td>\n",
       "      <td>23.75165</td>\n",
       "      <td>24.79626</td>\n",
       "      <td>23.29709</td>\n",
       "      <td>24.36054</td>\n",
       "      <td>24.32642</td>\n",
       "      <td>25.17010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>24.19614</td>\n",
       "      <td>25.39020</td>\n",
       "      <td>25.08374</td>\n",
       "      <td>25.13977</td>\n",
       "      <td>24.90289</td>\n",
       "      <td>25.20007</td>\n",
       "      <td>24.98975</td>\n",
       "      <td>25.11850</td>\n",
       "      <td>24.76849</td>\n",
       "      <td>25.48230</td>\n",
       "      <td>...</td>\n",
       "      <td>26.19327</td>\n",
       "      <td>23.99133</td>\n",
       "      <td>23.51892</td>\n",
       "      <td>23.53003</td>\n",
       "      <td>24.67722</td>\n",
       "      <td>23.54636</td>\n",
       "      <td>24.23114</td>\n",
       "      <td>23.50284</td>\n",
       "      <td>25.44403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>24.70395</td>\n",
       "      <td>25.13409</td>\n",
       "      <td>24.26135</td>\n",
       "      <td>25.24960</td>\n",
       "      <td>24.36804</td>\n",
       "      <td>24.75723</td>\n",
       "      <td>24.46268</td>\n",
       "      <td>24.38156</td>\n",
       "      <td>25.07089</td>\n",
       "      <td>24.78732</td>\n",
       "      <td>...</td>\n",
       "      <td>25.59448</td>\n",
       "      <td>23.46606</td>\n",
       "      <td>23.51770</td>\n",
       "      <td>22.84119</td>\n",
       "      <td>23.98505</td>\n",
       "      <td>23.29614</td>\n",
       "      <td>24.60431</td>\n",
       "      <td>23.35858</td>\n",
       "      <td>24.18527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>24.58746</td>\n",
       "      <td>25.00854</td>\n",
       "      <td>24.62543</td>\n",
       "      <td>25.01544</td>\n",
       "      <td>24.48535</td>\n",
       "      <td>24.21008</td>\n",
       "      <td>25.00281</td>\n",
       "      <td>24.90381</td>\n",
       "      <td>24.58243</td>\n",
       "      <td>24.78839</td>\n",
       "      <td>...</td>\n",
       "      <td>25.60501</td>\n",
       "      <td>23.14923</td>\n",
       "      <td>23.20480</td>\n",
       "      <td>23.74396</td>\n",
       "      <td>25.14468</td>\n",
       "      <td>23.04446</td>\n",
       "      <td>24.49085</td>\n",
       "      <td>24.31717</td>\n",
       "      <td>25.03567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>24.83115</td>\n",
       "      <td>25.27405</td>\n",
       "      <td>24.97046</td>\n",
       "      <td>23.97437</td>\n",
       "      <td>24.47699</td>\n",
       "      <td>24.77268</td>\n",
       "      <td>24.78253</td>\n",
       "      <td>24.60596</td>\n",
       "      <td>24.97238</td>\n",
       "      <td>24.99985</td>\n",
       "      <td>...</td>\n",
       "      <td>26.09607</td>\n",
       "      <td>23.27258</td>\n",
       "      <td>23.51999</td>\n",
       "      <td>23.42478</td>\n",
       "      <td>24.21814</td>\n",
       "      <td>23.31055</td>\n",
       "      <td>24.10541</td>\n",
       "      <td>23.64981</td>\n",
       "      <td>24.60822</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>24.70404</td>\n",
       "      <td>25.13794</td>\n",
       "      <td>24.96945</td>\n",
       "      <td>25.13675</td>\n",
       "      <td>24.69144</td>\n",
       "      <td>24.97977</td>\n",
       "      <td>24.67548</td>\n",
       "      <td>24.69925</td>\n",
       "      <td>25.07092</td>\n",
       "      <td>24.98904</td>\n",
       "      <td>...</td>\n",
       "      <td>24.78989</td>\n",
       "      <td>23.67621</td>\n",
       "      <td>23.51819</td>\n",
       "      <td>23.29773</td>\n",
       "      <td>24.44638</td>\n",
       "      <td>23.41928</td>\n",
       "      <td>23.97757</td>\n",
       "      <td>24.32642</td>\n",
       "      <td>24.04556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>25.07144</td>\n",
       "      <td>25.13531</td>\n",
       "      <td>24.36990</td>\n",
       "      <td>25.48380</td>\n",
       "      <td>24.57401</td>\n",
       "      <td>25.41254</td>\n",
       "      <td>25.19568</td>\n",
       "      <td>25.52853</td>\n",
       "      <td>25.25970</td>\n",
       "      <td>25.77139</td>\n",
       "      <td>...</td>\n",
       "      <td>25.18286</td>\n",
       "      <td>23.36044</td>\n",
       "      <td>23.93900</td>\n",
       "      <td>23.86032</td>\n",
       "      <td>23.97491</td>\n",
       "      <td>23.53680</td>\n",
       "      <td>24.46896</td>\n",
       "      <td>24.04507</td>\n",
       "      <td>24.59448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>24.94678</td>\n",
       "      <td>25.25278</td>\n",
       "      <td>24.84280</td>\n",
       "      <td>24.77609</td>\n",
       "      <td>25.11200</td>\n",
       "      <td>24.75189</td>\n",
       "      <td>24.87885</td>\n",
       "      <td>25.21011</td>\n",
       "      <td>25.85330</td>\n",
       "      <td>25.56836</td>\n",
       "      <td>...</td>\n",
       "      <td>25.18405</td>\n",
       "      <td>23.14505</td>\n",
       "      <td>23.50919</td>\n",
       "      <td>23.62741</td>\n",
       "      <td>24.55206</td>\n",
       "      <td>23.04117</td>\n",
       "      <td>24.09415</td>\n",
       "      <td>23.76245</td>\n",
       "      <td>24.45654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>24.44156</td>\n",
       "      <td>25.00836</td>\n",
       "      <td>24.84119</td>\n",
       "      <td>24.89835</td>\n",
       "      <td>24.68048</td>\n",
       "      <td>24.64710</td>\n",
       "      <td>24.77020</td>\n",
       "      <td>25.11075</td>\n",
       "      <td>25.15839</td>\n",
       "      <td>25.18024</td>\n",
       "      <td>...</td>\n",
       "      <td>25.48578</td>\n",
       "      <td>23.25708</td>\n",
       "      <td>23.18604</td>\n",
       "      <td>23.40985</td>\n",
       "      <td>24.66904</td>\n",
       "      <td>23.17301</td>\n",
       "      <td>23.71970</td>\n",
       "      <td>23.77396</td>\n",
       "      <td>24.74115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>25.57883</td>\n",
       "      <td>25.12225</td>\n",
       "      <td>25.55139</td>\n",
       "      <td>25.47083</td>\n",
       "      <td>25.33041</td>\n",
       "      <td>24.96396</td>\n",
       "      <td>25.30606</td>\n",
       "      <td>24.57913</td>\n",
       "      <td>25.75839</td>\n",
       "      <td>25.07153</td>\n",
       "      <td>...</td>\n",
       "      <td>25.49191</td>\n",
       "      <td>23.55707</td>\n",
       "      <td>24.05509</td>\n",
       "      <td>24.07614</td>\n",
       "      <td>24.44528</td>\n",
       "      <td>23.15979</td>\n",
       "      <td>25.10324</td>\n",
       "      <td>24.44983</td>\n",
       "      <td>24.60672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>25.19186</td>\n",
       "      <td>25.50617</td>\n",
       "      <td>24.60077</td>\n",
       "      <td>25.48099</td>\n",
       "      <td>25.42655</td>\n",
       "      <td>25.19168</td>\n",
       "      <td>24.97824</td>\n",
       "      <td>25.31781</td>\n",
       "      <td>25.55066</td>\n",
       "      <td>25.57181</td>\n",
       "      <td>...</td>\n",
       "      <td>25.68002</td>\n",
       "      <td>23.67194</td>\n",
       "      <td>23.71930</td>\n",
       "      <td>23.63513</td>\n",
       "      <td>24.54666</td>\n",
       "      <td>23.53793</td>\n",
       "      <td>24.08908</td>\n",
       "      <td>24.59927</td>\n",
       "      <td>24.73135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>25.20230</td>\n",
       "      <td>25.74103</td>\n",
       "      <td>25.43356</td>\n",
       "      <td>25.23453</td>\n",
       "      <td>25.43646</td>\n",
       "      <td>25.61295</td>\n",
       "      <td>25.19971</td>\n",
       "      <td>25.40863</td>\n",
       "      <td>25.65897</td>\n",
       "      <td>25.95016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.19009</td>\n",
       "      <td>23.75998</td>\n",
       "      <td>23.94724</td>\n",
       "      <td>23.84430</td>\n",
       "      <td>24.44476</td>\n",
       "      <td>24.00742</td>\n",
       "      <td>24.72870</td>\n",
       "      <td>24.16724</td>\n",
       "      <td>24.74560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>25.18289</td>\n",
       "      <td>25.38110</td>\n",
       "      <td>25.18024</td>\n",
       "      <td>25.48029</td>\n",
       "      <td>25.63098</td>\n",
       "      <td>25.73325</td>\n",
       "      <td>24.86350</td>\n",
       "      <td>25.42084</td>\n",
       "      <td>25.64047</td>\n",
       "      <td>25.47333</td>\n",
       "      <td>...</td>\n",
       "      <td>25.27060</td>\n",
       "      <td>23.98160</td>\n",
       "      <td>24.03442</td>\n",
       "      <td>24.19855</td>\n",
       "      <td>24.76816</td>\n",
       "      <td>24.14426</td>\n",
       "      <td>24.95731</td>\n",
       "      <td>24.59708</td>\n",
       "      <td>24.86298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>25.06046</td>\n",
       "      <td>25.24048</td>\n",
       "      <td>25.53430</td>\n",
       "      <td>24.99799</td>\n",
       "      <td>25.09933</td>\n",
       "      <td>24.95724</td>\n",
       "      <td>25.81555</td>\n",
       "      <td>25.19739</td>\n",
       "      <td>25.74136</td>\n",
       "      <td>25.16293</td>\n",
       "      <td>...</td>\n",
       "      <td>24.87146</td>\n",
       "      <td>23.03009</td>\n",
       "      <td>24.03830</td>\n",
       "      <td>23.95770</td>\n",
       "      <td>25.79822</td>\n",
       "      <td>22.66364</td>\n",
       "      <td>25.08643</td>\n",
       "      <td>24.03143</td>\n",
       "      <td>25.14664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>24.67053</td>\n",
       "      <td>24.99020</td>\n",
       "      <td>25.28839</td>\n",
       "      <td>25.46359</td>\n",
       "      <td>25.40866</td>\n",
       "      <td>24.84756</td>\n",
       "      <td>24.85449</td>\n",
       "      <td>24.98889</td>\n",
       "      <td>25.43405</td>\n",
       "      <td>25.06406</td>\n",
       "      <td>...</td>\n",
       "      <td>25.66187</td>\n",
       "      <td>23.23767</td>\n",
       "      <td>23.91659</td>\n",
       "      <td>24.18204</td>\n",
       "      <td>24.75763</td>\n",
       "      <td>23.88477</td>\n",
       "      <td>24.82208</td>\n",
       "      <td>24.30557</td>\n",
       "      <td>25.40750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>25.29895</td>\n",
       "      <td>25.60233</td>\n",
       "      <td>25.40549</td>\n",
       "      <td>25.22012</td>\n",
       "      <td>24.87308</td>\n",
       "      <td>25.38123</td>\n",
       "      <td>25.17206</td>\n",
       "      <td>25.29022</td>\n",
       "      <td>25.73035</td>\n",
       "      <td>25.05389</td>\n",
       "      <td>...</td>\n",
       "      <td>27.25143</td>\n",
       "      <td>23.64246</td>\n",
       "      <td>24.23828</td>\n",
       "      <td>24.05740</td>\n",
       "      <td>24.75720</td>\n",
       "      <td>24.23682</td>\n",
       "      <td>24.57175</td>\n",
       "      <td>24.56815</td>\n",
       "      <td>25.12949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>25.17365</td>\n",
       "      <td>25.10172</td>\n",
       "      <td>24.81860</td>\n",
       "      <td>25.33408</td>\n",
       "      <td>24.65823</td>\n",
       "      <td>24.94394</td>\n",
       "      <td>25.27774</td>\n",
       "      <td>25.39166</td>\n",
       "      <td>25.43402</td>\n",
       "      <td>24.65769</td>\n",
       "      <td>...</td>\n",
       "      <td>33.65805</td>\n",
       "      <td>24.15677</td>\n",
       "      <td>26.04568</td>\n",
       "      <td>23.48694</td>\n",
       "      <td>24.75809</td>\n",
       "      <td>23.01379</td>\n",
       "      <td>24.82254</td>\n",
       "      <td>23.73499</td>\n",
       "      <td>25.54645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>764 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    22.62949  23.34601  22.84607  24.27225  24.22751  24.99457  27.39221   \n",
       "1    23.16067  23.59763  25.04761  24.74619  27.40509  27.20163  28.14008   \n",
       "2    23.03558  24.24997  23.59360  24.87021  25.99951  27.53504  27.61453   \n",
       "3    22.25803  23.60641  22.50025  24.63440  23.02280  26.32965  24.39380   \n",
       "4    22.11905  23.36346  22.37064  22.95017  22.00073  22.74686  22.73328   \n",
       "5    22.24774  22.82923  22.61456  22.57074  23.90958  23.42151  29.41101   \n",
       "6    22.52435  23.08780  22.99613  23.42499  27.74887  27.32492  32.70804   \n",
       "7    22.37411  22.70657  23.83859  25.60977  30.59570  31.41663  33.40170   \n",
       "8    21.86481  23.21832  25.19602  27.96146  31.86359  33.18375  32.81717   \n",
       "9    22.52863  23.10373  25.43658  28.09415  31.44864  32.99234  32.91727   \n",
       "10   21.87976  23.23874  24.48318  26.80637  31.04550  32.57886  33.03000   \n",
       "11   22.01593  23.12048  23.14093  26.81812  29.89594  33.31625  33.93530   \n",
       "12   21.73358  22.46457  21.51373  23.94440  24.70673  29.95139  31.09051   \n",
       "13   21.60510  22.83392  22.02408  22.08896  22.82910  25.91690  28.29785   \n",
       "14   21.35684  22.45941  22.04224  22.60257  23.18390  24.70514  27.57144   \n",
       "15   21.90445  22.48276  21.67545  22.24854  22.84360  23.24094  26.71466   \n",
       "16   22.17194  23.01645  21.67660  22.62653  22.95731  23.81754  25.31375   \n",
       "17   21.24469  22.75302  21.05750  22.99377  22.73932  23.70319  25.64670   \n",
       "18   22.04459  22.74832  20.81064  22.25830  23.09250  24.50583  25.44620   \n",
       "19   22.05759  22.23212  21.82614  22.26892  22.87967  24.17767  25.78269   \n",
       "20   21.65164  22.50772  21.44568  22.40412  22.76193  23.62250  24.90985   \n",
       "21   21.79492  22.63193  21.58054  22.39667  22.77148  23.38864  24.59131   \n",
       "22   22.07364  22.11783  21.84213  22.16305  23.34537  23.40137  24.60248   \n",
       "23   22.07947  21.99545  22.09671  22.29648  21.88205  23.06897  23.39655   \n",
       "24   21.40631  22.39935  21.59253  22.30396  21.64908  22.61768  22.39102   \n",
       "25   21.41837  22.12738  21.10294  21.92493  21.20355  22.15060  22.62564   \n",
       "26   21.70432  21.87775  21.99606  22.31107  21.56372  22.39517  22.41864   \n",
       "27   21.29791  21.36118  20.86432  21.95465  22.12842  22.52411  22.41464   \n",
       "28   21.31738  21.88889  22.00983  22.44550  22.03265  22.97925  22.54337   \n",
       "29   21.43283  22.29840  21.99240  22.21118  22.69519  22.87704  25.38934   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "734  25.11514  25.41595  25.12030  25.51492  24.93973  25.44421  25.23868   \n",
       "735  24.71115  25.90851  24.74731  24.93405  24.71451  25.34497  25.01752   \n",
       "736  25.11624  25.02682  24.17734  25.26712  24.94064  24.77573  25.02786   \n",
       "737  24.85785  25.16965  25.23157  24.93448  24.93356  25.22943  24.91470   \n",
       "738  24.34683  25.04321  25.10791  25.39975  24.38895  25.11804  25.33124   \n",
       "739  24.71558  25.03067  24.86289  24.68625  25.02460  24.99725  25.11017   \n",
       "740  25.84372  25.14862  24.15433  25.14734  25.02460  24.55344  25.32153   \n",
       "741  24.83258  25.51459  24.97784  25.26343  24.70935  25.32306  25.11783   \n",
       "742  25.59906  24.77402  24.75009  25.49728  24.49210  24.44424  24.79785   \n",
       "743  24.71439  24.90176  24.38992  25.03357  24.70139  25.53751  24.68530   \n",
       "744  24.84036  25.39636  25.68259  25.14584  25.02365  25.31519  25.42627   \n",
       "745  25.20926  25.39636  24.26355  25.37903  24.69333  24.98883  24.88944   \n",
       "746  25.21127  25.63919  24.73779  25.14011  24.58737  24.87369  25.10281   \n",
       "747  24.83337  25.01309  24.97241  25.83484  24.37103  25.19751  25.62964   \n",
       "748  24.19614  25.39020  25.08374  25.13977  24.90289  25.20007  24.98975   \n",
       "749  24.70395  25.13409  24.26135  25.24960  24.36804  24.75723  24.46268   \n",
       "750  24.58746  25.00854  24.62543  25.01544  24.48535  24.21008  25.00281   \n",
       "751  24.83115  25.27405  24.97046  23.97437  24.47699  24.77268  24.78253   \n",
       "752  24.70404  25.13794  24.96945  25.13675  24.69144  24.97977  24.67548   \n",
       "753  25.07144  25.13531  24.36990  25.48380  24.57401  25.41254  25.19568   \n",
       "754  24.94678  25.25278  24.84280  24.77609  25.11200  24.75189  24.87885   \n",
       "755  24.44156  25.00836  24.84119  24.89835  24.68048  24.64710  24.77020   \n",
       "756  25.57883  25.12225  25.55139  25.47083  25.33041  24.96396  25.30606   \n",
       "757  25.19186  25.50617  24.60077  25.48099  25.42655  25.19168  24.97824   \n",
       "758  25.20230  25.74103  25.43356  25.23453  25.43646  25.61295  25.19971   \n",
       "759  25.18289  25.38110  25.18024  25.48029  25.63098  25.73325  24.86350   \n",
       "760  25.06046  25.24048  25.53430  24.99799  25.09933  24.95724  25.81555   \n",
       "761  24.67053  24.99020  25.28839  25.46359  25.40866  24.84756  24.85449   \n",
       "762  25.29895  25.60233  25.40549  25.22012  24.87308  25.38123  25.17206   \n",
       "763  25.17365  25.10172  24.81860  25.33408  24.65823  24.94394  25.27774   \n",
       "\n",
       "          7         8         9   ...        759       760       761  \\\n",
       "0    26.94012  27.34689  27.80975 ...   25.27432  22.86929  22.75967   \n",
       "1    27.87192  28.14847  27.80102 ...   23.29489  22.53711  22.20065   \n",
       "2    28.60287  27.45639  27.70782 ...   22.45697  21.56348  22.20950   \n",
       "3    27.77655  26.36633  27.61267 ...   23.10901  21.89667  22.56369   \n",
       "4    22.88919  22.98193  23.40122 ...   23.62778  22.02560  21.54199   \n",
       "5    25.57358  31.09058  27.32391 ...   27.53855  22.44513  26.72360   \n",
       "6    31.86749  32.91443  31.11096 ...   27.65057  26.46704  26.62717   \n",
       "7    34.25433  34.12695  33.94504 ...   26.92328  26.37424  27.03885   \n",
       "8    33.36041  33.39514  34.12235 ...   26.64026  25.84201  26.19956   \n",
       "9    33.77081  33.67676  33.58032 ...   27.35138  25.64829  26.19898   \n",
       "10   32.98303  33.40576  33.76898 ...   26.75708  25.54871  26.32297   \n",
       "11   33.38922  34.06494  33.77905 ...   26.96378  26.81216  26.32636   \n",
       "12   33.68460  33.68460  34.42801 ...   27.35434  27.01865  26.09277   \n",
       "13   31.69977  32.47879  33.60327 ...   27.99423  26.50235  26.12140   \n",
       "14   30.19763  30.57199  32.67972 ...   25.36157  25.26813  22.84131   \n",
       "15   28.03738  29.58966  29.23184 ...   22.72952  21.62570  21.47946   \n",
       "16   27.73398  29.49326  29.33792 ...   22.94269  21.30749  21.36768   \n",
       "17   27.62906  29.50140  29.72510 ...   22.94949  21.52469  21.37412   \n",
       "18   27.54132  29.32816  29.74796 ...   22.65936  21.43625  21.28198   \n",
       "19   28.07236  29.53482  29.75775 ...   23.09647  21.77469  21.52301   \n",
       "20   28.49780  29.13989  29.57425 ...   21.70679  21.56928  21.40186   \n",
       "21   26.92798  28.16141  28.79175 ...   21.50253  21.45084  21.86462   \n",
       "22   26.09586  27.67517  27.72376 ...   21.94357  21.35645  21.53830   \n",
       "23   24.71884  24.74893  26.84152 ...   22.16425  21.47592  21.88525   \n",
       "24   23.21118  23.09219  24.83814 ...   22.05051  21.59433  21.76480   \n",
       "25   22.32889  22.68591  23.50516 ...   22.06314  21.14789  21.55130   \n",
       "26   22.78177  23.43085  24.13342 ...   21.86972  21.38397  21.79846   \n",
       "27   22.57669  23.42728  23.32672 ...   21.75671  20.96216  22.01792   \n",
       "28   23.22916  23.96118  25.76508 ...   22.09863  21.61487  21.58798   \n",
       "29   23.35007  25.99094  24.46143 ...   21.11368  21.19037  20.99921   \n",
       "..        ...       ...       ... ...        ...       ...       ...   \n",
       "734  25.24881  24.80594  25.21539 ...   25.92810  23.80734  23.87439   \n",
       "735  24.95053  24.90207  25.43063 ...   26.22876  23.93301  23.65390   \n",
       "736  25.23380  25.40241  25.10181 ...   26.12918  23.68912  24.19858   \n",
       "737  24.62653  25.29599  25.02109 ...   25.82364  23.70734  23.97864   \n",
       "738  25.04117  25.09100  25.21469 ...   25.31635  23.29224  23.43356   \n",
       "739  25.23709  25.57648  24.90799 ...   25.30637  22.86005  23.20740   \n",
       "740  24.91812  25.27969  24.70364 ...   26.40573  23.89502  24.28470   \n",
       "741  25.13705  25.19440  25.21219 ...   26.72226  23.91257  24.29721   \n",
       "742  24.91846  25.58246  24.90109 ...   26.70703  24.10275  24.07181   \n",
       "743  24.81754  25.47693  25.39642 ...   26.00565  24.41367  23.85294   \n",
       "744  24.91678  25.87173  25.39093 ...   25.80582  23.89313  23.85294   \n",
       "745  25.53973  24.97314  25.58682 ...   26.59491  23.68567  24.16757   \n",
       "746  24.80655  25.37137  25.38461 ...   26.19931  24.30212  24.59808   \n",
       "747  25.21976  24.97394  25.38199 ...   26.29816  23.88367  24.06198   \n",
       "748  25.11850  24.76849  25.48230 ...   26.19327  23.99133  23.51892   \n",
       "749  24.38156  25.07089  24.78732 ...   25.59448  23.46606  23.51770   \n",
       "750  24.90381  24.58243  24.78839 ...   25.60501  23.14923  23.20480   \n",
       "751  24.60596  24.97238  24.99985 ...   26.09607  23.27258  23.51999   \n",
       "752  24.69925  25.07092  24.98904 ...   24.78989  23.67621  23.51819   \n",
       "753  25.52853  25.25970  25.77139 ...   25.18286  23.36044  23.93900   \n",
       "754  25.21011  25.85330  25.56836 ...   25.18405  23.14505  23.50919   \n",
       "755  25.11075  25.15839  25.18024 ...   25.48578  23.25708  23.18604   \n",
       "756  24.57913  25.75839  25.07153 ...   25.49191  23.55707  24.05509   \n",
       "757  25.31781  25.55066  25.57181 ...   25.68002  23.67194  23.71930   \n",
       "758  25.40863  25.65897  25.95016 ...   25.19009  23.75998  23.94724   \n",
       "759  25.42084  25.64047  25.47333 ...   25.27060  23.98160  24.03442   \n",
       "760  25.19739  25.74136  25.16293 ...   24.87146  23.03009  24.03830   \n",
       "761  24.98889  25.43405  25.06406 ...   25.66187  23.23767  23.91659   \n",
       "762  25.29022  25.73035  25.05389 ...   27.25143  23.64246  24.23828   \n",
       "763  25.39166  25.43402  24.65769 ...   33.65805  24.15677  26.04568   \n",
       "\n",
       "          762       763       764       765       766       767  768  \n",
       "0    22.38684  22.88013  22.94119  22.99555  22.63037  23.33066    2  \n",
       "1    22.37799  22.64114  21.91843  22.99634  23.05240  22.60111    2  \n",
       "2    22.61514  22.40997  22.42819  22.61395  23.05298  23.48731    2  \n",
       "3    22.38712  22.90918  22.18204  22.10751  22.77466  23.50760    2  \n",
       "4    22.05508  22.78049  21.82272  22.62360  22.51157  23.20691    2  \n",
       "5    23.09903  27.47080  23.32593  26.35037  23.63992  25.92902    2  \n",
       "6    28.45911  28.85034  27.50784  26.86649  26.02933  26.92896    2  \n",
       "7    27.01385  26.07596  25.69312  26.34161  25.90204  25.91846    2  \n",
       "8    26.21033  26.44818  25.68188  25.34921  25.75110  26.08591    2  \n",
       "9    26.56589  26.56338  26.18738  25.98495  26.04471  26.22647    2  \n",
       "10   26.23163  25.99960  25.33429  25.74826  25.63361  26.10413    2  \n",
       "11   25.90359  26.46802  25.47122  26.25971  25.50830  26.53262    2  \n",
       "12   27.37488  28.06040  26.69430  27.12216  25.64749  26.79062    2  \n",
       "13   27.47952  27.39694  26.55670  26.38022  25.75241  24.95172    2  \n",
       "14   25.91684  23.55621  25.47690  23.19327  23.80368  23.24545    2  \n",
       "15   22.56009  21.74496  21.72848  21.75232  22.83026  23.25714    2  \n",
       "16   21.26559  22.47235  22.37424  22.54459  22.55234  22.67609    2  \n",
       "17   21.97769  22.35831  21.48108  22.02469  22.55109  22.09515    2  \n",
       "18   21.87119  21.76950  21.86862  22.42493  21.81622  22.38440    2  \n",
       "19   21.40729  21.90558  22.26239  21.64844  22.11862  23.13190    2  \n",
       "20   21.77722  22.38107  21.25391  21.63956  22.42136  22.39053    2  \n",
       "21   21.40936  22.51175  22.01025  22.70367  21.97470  22.98636    2  \n",
       "22   21.42532  22.40463  21.64328  22.32340  21.99188  22.56226    2  \n",
       "23   22.02985  22.53336  21.90909  22.46350  22.29205  22.57217    2  \n",
       "24   22.51328  22.28427  21.91980  22.45529  22.44907  22.12213    2  \n",
       "25   22.14853  22.17661  21.39792  22.20551  21.56708  22.72351    2  \n",
       "26   21.45471  22.07779  21.67273  22.22833  21.87860  22.89502    2  \n",
       "27   21.35269  22.07098  21.17746  21.69306  21.60654  22.15378    2  \n",
       "28   21.70621  22.69760  21.68622  21.98172  21.60248  22.76752    2  \n",
       "29   21.59988  21.95111  21.44302  21.56189  22.34039  21.86041    2  \n",
       "..        ...       ...       ...       ...       ...       ...  ...  \n",
       "734  24.45477  24.24927  24.41800  24.51227  23.93637  24.35904    1  \n",
       "735  24.01929  24.00851  23.69748  24.49203  24.20822  24.74823    1  \n",
       "736  23.65027  23.78937  23.43134  24.01227  24.47513  24.92017    1  \n",
       "737  23.55521  24.47638  23.57199  24.25906  23.24814  24.49747    1  \n",
       "738  23.10364  24.58539  23.20853  24.25348  24.49905  24.91095    1  \n",
       "739  23.20190  24.34534  23.43741  24.61899  23.93054  24.90018    1  \n",
       "740  23.30978  24.68988  23.30917  24.36865  24.06320  24.76084    1  \n",
       "741  23.77390  25.38339  23.92139  24.99075  24.60321  25.16617    1  \n",
       "742  23.31064  24.23129  23.43219  24.49442  24.34012  24.76004    1  \n",
       "743  23.53680  24.68759  23.43134  24.99097  23.78488  24.33862    1  \n",
       "744  23.98749  25.03104  23.79468  24.61649  23.78387  25.31418    1  \n",
       "745  24.10040  24.56506  23.06201  24.23306  24.47391  24.47092    1  \n",
       "746  23.98376  24.45261  23.91242  24.23566  23.64264  24.19397    1  \n",
       "747  23.75165  24.79626  23.29709  24.36054  24.32642  25.17010    1  \n",
       "748  23.53003  24.67722  23.54636  24.23114  23.50284  25.44403    1  \n",
       "749  22.84119  23.98505  23.29614  24.60431  23.35858  24.18527    1  \n",
       "750  23.74396  25.14468  23.04446  24.49085  24.31717  25.03567    1  \n",
       "751  23.42478  24.21814  23.31055  24.10541  23.64981  24.60822    1  \n",
       "752  23.29773  24.44638  23.41928  23.97757  24.32642  24.04556    1  \n",
       "753  23.86032  23.97491  23.53680  24.46896  24.04507  24.59448    1  \n",
       "754  23.62741  24.55206  23.04117  24.09415  23.76245  24.45654    1  \n",
       "755  23.40985  24.66904  23.17301  23.71970  23.77396  24.74115    1  \n",
       "756  24.07614  24.44528  23.15979  25.10324  24.44983  24.60672    1  \n",
       "757  23.63513  24.54666  23.53793  24.08908  24.59927  24.73135    1  \n",
       "758  23.84430  24.44476  24.00742  24.72870  24.16724  24.74560    1  \n",
       "759  24.19855  24.76816  24.14426  24.95731  24.59708  24.86298    1  \n",
       "760  23.95770  25.79822  22.66364  25.08643  24.03143  25.14664    1  \n",
       "761  24.18204  24.75763  23.88477  24.82208  24.30557  25.40750    1  \n",
       "762  24.05740  24.75720  24.23682  24.57175  24.56815  25.12949    1  \n",
       "763  23.48694  24.75809  23.01379  24.82254  23.73499  25.54645    1  \n",
       "\n",
       "[764 rows x 769 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = df.iloc[:, -1]\n",
    "df = df.iloc[:, :-1]\n",
    "\n",
    "# 让脸部温度单独保存，环境温度设计为统一值\n",
    "ta = df.min(axis=1)\n",
    "\n",
    "df_face = pd.DataFrame()\n",
    "# df_face 脸部温度+其他区域温度置换为环境温度\n",
    "df_onlyface = pd.DataFrame()\n",
    "# df_onlyface 只有脸部温度点\n",
    "df_ave_ta = pd.DataFrame()\n",
    "\n",
    "for i, minTa in zip(df.values, ta):\n",
    "    face = []\n",
    "    onlyface = []\n",
    "    ave_ta = []\n",
    "    for j in i:\n",
    "        try:\n",
    "        # 因为检查到有一些数字不是float是str，像21.42346.1，不知是什么原因导致的，\n",
    "            if j - minTa > 7:\n",
    "                face.append(j)\n",
    "#                 onlyface.append(j)\n",
    "            else:\n",
    "                face.append(minTa)\n",
    "                ave_ta.append(j)\n",
    "        except:\n",
    "            j = float(j[:6])\n",
    "            if j - minTa > 7:\n",
    "                face.append(j)\n",
    "#                 onlyface.append(j)\n",
    "            else:\n",
    "                face.append(minTa)\n",
    "                ave_ta.append(j)\n",
    "    face_todf = pd.DataFrame(face).T\n",
    "    ave_ta_todf = pd.DataFrame(ave_ta).T\n",
    "#     onlyface_todf = pd.DataFrame(onlyface).T\n",
    "    df_face = pd.concat([df_face, face_todf], axis = 0, ignore_index=True)\n",
    "    df_ave_ta = pd.concat([df_ave_ta, ave_ta_todf], axis=0, ignore_index=True)\n",
    "#     df_onlyface = pd.concat([df_onlyface, onlyface_todf], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model for outlier detection (default)\n",
    "clf = LocalOutlierFactor(n_neighbors=40, contamination=0.05)\n",
    "# use fit_predict to compute the predicted labels of the training samples\n",
    "# (when LOF is used for outlier detection, the estimator has no predict,\n",
    "# decision_function and score_samples methods).\n",
    "y_pred = clf.fit_predict(df_face)\n",
    "# n_errors = (y_pred != ground_truth).sum()\n",
    "X_scores = clf.negative_outlier_factor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_index = np.argpartition(X_scores, int(df_face.shape[0]*0.05))[:int(df_face.shape[0]*0.05)]\n",
    "\n",
    "# 去除掉5%的异常样本\n",
    "df = df.drop(min_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = ta.iloc[df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = target_column.iloc[df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column.index = np.arange(target_column.shape[0])\n",
    "# 因为df_Onlyface是0到725，target_column虽然也是726行，但是pd.concat在连的时候，ignore_index是指忽略axis=1这个轴上的index，不是Axis=0\n",
    "# 但是又不能指定outter，因为df_onlyface的index是无意义的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, minTa in zip(df.values, ta):\n",
    "#     face = []\n",
    "    onlyface = []\n",
    "    for j in i:\n",
    "        try:\n",
    "        # 因为检查到有一些数字不是float是str，像21.42346.1，不知是什么原因导致的，\n",
    "            if j - minTa > 7:\n",
    "#                 face.append(j)\n",
    "                onlyface.append(j)\n",
    "#             else:\n",
    "#                 face.append(minTa)\n",
    "        except:\n",
    "            j = float(j[:6])\n",
    "            if j - minTa > 7:\n",
    "#                 face.append(j)\n",
    "                onlyface.append(j)\n",
    "#             else:\n",
    "#                 face.append(minTa)\n",
    "#     face_todf = pd.DataFrame(face).T\n",
    "    onlyface_todf = pd.DataFrame(onlyface).T\n",
    "#     df_face = pd.concat([df_face, face_todf], axis = 0, ignore_index=True)\n",
    "    df_onlyface = pd.concat([df_onlyface, onlyface_todf], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onlyface_temp = pd.concat([target_column, df_onlyface], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave_ta = df_ave_ta.iloc[df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ave_ta.index = np.arange(df_ave_ta.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = pd.DataFrame(df_onlyface.skew(axis=1))\n",
    "maxTemp = pd.DataFrame(df_onlyface.max(axis=1))\n",
    "minTemp = pd.DataFrame(df_onlyface.min(axis=1))\n",
    "meanTemp = pd.DataFrame(df_onlyface.mean(axis=1))\n",
    "ave_ta = df_ave_ta.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定划分bin的点\n",
    "bins = [28.3, 28.6, 28.9, 29.2, 29.5,\n",
    " 29.8, 30.1, 30.4, 30.7, 31.0,  31.3,\n",
    " 31.6, 31.9, 32.2, 32.5,  32.8, 33.1,\n",
    " 33.4, 33.7, 34.0,  34.3, 34.6, 34.9,\n",
    " 35.2, 35.5, 35.8, 36.1, 36.4, 36.7]\n",
    "\n",
    "highest_bin_list = []\n",
    "for i in df_onlyface.values:\n",
    "    i = [j for j in i if not np.isnan(j)]\n",
    "    N, _ = np.histogram(np.clip(i,28.3,36.7), bins=bins)\n",
    "    highest_bin = (bins[N.argmax()]+bins[N.argmax()+1])/2\n",
    "    # 返回各区域频数N\n",
    "    highest_bin_list.append(highest_bin)\n",
    "\n",
    "modeTemp = pd.DataFrame(highest_bin_list, index=df_onlyface.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([skewness, maxTemp, minTemp, meanTemp, modeTemp, ave_ta], axis=1) \n",
    "# 默认是outer所以每一列都要改成0-725，之前的ta的index需要重置一下\n",
    "features.columns = ['skewness', 'maxTemp', 'minTemp', 'meanTemp', 'modeTemp', 'ta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['max_minus_min'] = features['maxTemp'] - features['minTemp']\n",
    "features['mode_minus_ta'] = features['modeTemp'] - features['ta']\n",
    "features['mean_minus_ta'] = features['meanTemp'] - features['ta']\n",
    "features['max_minus_ta'] = features['maxTemp'] - features['ta']\n",
    "features['min_minus_ta'] = features['minTemp'] - features['ta']\n",
    "# features['mode_minus_min'] = features['modeTemp'] - features['minTemp']\n",
    "# features['mean_minus_min'] = features['meanTemp'] - features['minTemp']\n",
    "features['max_minus_mean'] = features['maxTemp'] - features['meanTemp']\n",
    "# features['mode_squa'] = features['modeTemp'] ** 2\n",
    "# features['mean_squa'] = features['meanTemp'] ** 2\n",
    "# features['max_squa'] = features['maxTemp'] ** 2\n",
    "# features['mode_cub'] = features['modeTemp'] ** 3\n",
    "# features['mean_cub'] = features['meanTemp'] ** 3\n",
    "# features['max_cub'] = features['maxTemp'] ** 3\n",
    "features = features.drop([\"minTemp\"], axis=1)\n",
    "features['target'] = target_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skewness          0.250269\n",
       "maxTemp           0.540261\n",
       "meanTemp          0.763666\n",
       "modeTemp          0.667578\n",
       "ta                1.302855\n",
       "max_minus_min     1.112634\n",
       "mode_minus_ta     0.871758\n",
       "mean_minus_ta     0.706516\n",
       "max_minus_ta      0.934096\n",
       "min_minus_ta      0.564584\n",
       "max_minus_mean    0.342632\n",
       "target            0.692136\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# featuresCorr = features.corr('spearman')\n",
    "# fig = plt.figure(figsize=(20, 20))\n",
    "# # plt.subplots((1,1,1)) # 设置画面大小\n",
    "# mask = np.zeros_like(featuresCorr)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# sns.heatmap(featuresCorr, annot=True, vmax=1, square=True, mask=mask, cbar=False)\n",
    "# # plt.savefig('I:\\graduation\\论文\\images\\corr_before', dpi=200)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featuresCorr.to_csv(path_or_buf='I:\\graduation\\论文\\\\featuresCorr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = features.drop(['target', 'maxTemp', 'meanTemp', 'modeTemp', 'max_minus_ta', 'max_minus_mean'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "features_scaler = std.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = features_scaler\n",
    "target = target_column.values\n",
    "\n",
    "train_X,test_X, train_y, test_y = train_test_split(train,\n",
    "                                                   target,\n",
    "                                                   test_size = 0.1,\n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# clf = ExtraTreesClassifier(bootstrap=True, oob_score=True)\n",
    "# clf = clf.fit(train_X, train_y)\n",
    "# print(clf.feature_importances_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-86db3ab18325>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# print(features.columns[model.get_support(indices=True)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\feature_selection\\from_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \"Since 'prefit=True', call transform directly\")\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_oob_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;31m# Decapsulate classes_ attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_set_oob_score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    446\u001b[0m                 estimator.random_state, n_samples)\n\u001b[0;32m    447\u001b[0m             p_estimator = estimator.predict_proba(X[unsampled_indices, :],\n\u001b[1;32m--> 448\u001b[1;33m                                                   check_input=False)\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tree_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(bootstrap=True, oob_score=True)\n",
    "count = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0}\n",
    "for i in range(1000):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "    model = SelectFromModel(clf)\n",
    "    model.fit(train_X, train_y)\n",
    "    # print(features.columns[model.get_support(indices=True)])\n",
    "    for j in model.get_support(indices=True):\n",
    "        count[j] += 1\n",
    "    # X_new = model.transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.columns)\n",
    "# X_new = np.concatenate((train_X[:, 2].reshape(-1,1), train_X[:, 4:7]), axis=1)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.concatenate((train_X[:, 1:3], train_X[:, 4].reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得出结果：1ta, 2max_minus_min, 4mean_minus_ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "gpc = GaussianProcessClassifier(1.0 * RBF(1.0), max_iter_predict=500, n_restarts_optimizer=5, warm_start=False, random_state=1, multi_class='one_vs_rest', n_jobs=-1)\n",
    "# gpc.fit(X_new, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N, bins, patches = plt.hist(X_new[:,0],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-efa101eceafc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mcrs_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test_X_com = np.concatenate((test_X[:, 1:3], test_X[:, 4:6]), axis=1)\n",
    "# 这个需要改为对应的特征\n",
    "\n",
    "# gpc_score = round(gpc.score(test_X_com, test_y) * 100, 2)\n",
    "# print(gpc_score)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "crs_val = cross_val_score(gpc, train_new, target, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.60585681e-01, 3.30973198e-02, 1.06316999e-01],\n",
       "       [6.74625163e-01, 1.44809139e-01, 1.80565698e-01],\n",
       "       [9.22121770e-01, 1.89730434e-02, 5.89051870e-02],\n",
       "       [7.99104757e-01, 7.33834703e-02, 1.27511773e-01],\n",
       "       [5.88919933e-03, 9.63263117e-01, 3.08476835e-02],\n",
       "       [1.56286157e-02, 9.64102065e-01, 2.02693197e-02],\n",
       "       [8.56820846e-01, 5.62413524e-02, 8.69378014e-02],\n",
       "       [5.98264582e-01, 1.72941520e-01, 2.28793898e-01],\n",
       "       [1.01095452e-01, 7.10287841e-01, 1.88616707e-01],\n",
       "       [9.95153097e-02, 6.87792603e-01, 2.12692087e-01],\n",
       "       [8.18635410e-01, 6.69203032e-02, 1.14444287e-01],\n",
       "       [7.73812293e-01, 1.08063272e-01, 1.18124435e-01],\n",
       "       [4.89146088e-03, 2.03588903e-01, 7.91519636e-01],\n",
       "       [1.00327133e-03, 9.87216039e-01, 1.17806896e-02],\n",
       "       [9.23021407e-01, 2.69984977e-02, 4.99800951e-02],\n",
       "       [8.19046476e-03, 9.81851633e-01, 9.95790243e-03],\n",
       "       [2.03522329e-03, 1.13654867e-01, 8.84309909e-01],\n",
       "       [8.09377492e-01, 4.67231466e-02, 1.43899362e-01],\n",
       "       [9.01049890e-01, 1.83572935e-02, 8.05928163e-02],\n",
       "       [9.44545521e-01, 1.12110692e-02, 4.42434100e-02],\n",
       "       [8.22544732e-03, 1.03691612e-02, 9.81405391e-01],\n",
       "       [7.63461766e-03, 9.81071388e-01, 1.12939947e-02],\n",
       "       [1.49988648e-01, 8.38626726e-01, 1.13846260e-02],\n",
       "       [3.68152121e-03, 9.87008839e-01, 9.30964009e-03],\n",
       "       [9.27378876e-01, 1.08389692e-02, 6.17821547e-02],\n",
       "       [7.21946425e-01, 1.87834870e-01, 9.02187044e-02],\n",
       "       [7.85864783e-01, 7.02668434e-02, 1.43868374e-01],\n",
       "       [7.70328917e-01, 7.70690775e-02, 1.52602005e-01],\n",
       "       [1.43607839e-01, 5.97060071e-01, 2.59332090e-01],\n",
       "       [7.41792714e-01, 1.31751682e-01, 1.26455605e-01],\n",
       "       [8.42703889e-01, 7.60849995e-02, 8.12111110e-02],\n",
       "       [7.16361922e-01, 1.34533045e-01, 1.49105033e-01],\n",
       "       [8.46362159e-01, 6.13336921e-02, 9.23041488e-02],\n",
       "       [9.67602437e-04, 9.91982536e-01, 7.04986127e-03],\n",
       "       [2.77578960e-01, 7.07381541e-01, 1.50394987e-02],\n",
       "       [9.32663968e-01, 1.63751525e-02, 5.09608790e-02],\n",
       "       [8.90141955e-01, 3.15512263e-02, 7.83068185e-02],\n",
       "       [1.88996876e-01, 7.97017432e-01, 1.39856920e-02],\n",
       "       [7.57321990e-02, 3.16620092e-01, 6.07647709e-01],\n",
       "       [8.61190808e-02, 7.04583497e-01, 2.09297422e-01],\n",
       "       [6.57082994e-01, 1.32695022e-01, 2.10221985e-01],\n",
       "       [8.31228120e-01, 5.19800277e-02, 1.16791852e-01],\n",
       "       [1.36053593e-03, 9.73927868e-01, 2.47115960e-02],\n",
       "       [8.70365777e-01, 4.85968020e-02, 8.10374211e-02],\n",
       "       [4.06551254e-03, 9.57599797e-01, 3.83346905e-02],\n",
       "       [8.60934020e-01, 5.01805609e-02, 8.88854196e-02],\n",
       "       [8.91214478e-01, 3.86985545e-02, 7.00869674e-02],\n",
       "       [2.83749072e-03, 9.84013413e-01, 1.31490961e-02],\n",
       "       [8.05076975e-01, 5.89799832e-02, 1.35943042e-01],\n",
       "       [8.04687138e-01, 7.26096611e-02, 1.22703201e-01],\n",
       "       [5.18171969e-03, 9.90606460e-01, 4.21182071e-03],\n",
       "       [9.34467685e-01, 1.47284290e-02, 5.08038856e-02],\n",
       "       [9.39000206e-01, 1.48172989e-02, 4.61824953e-02],\n",
       "       [8.91382703e-01, 1.88952291e-02, 8.97220674e-02],\n",
       "       [1.80636008e-02, 9.76798389e-01, 5.13801005e-03],\n",
       "       [8.72583895e-01, 7.30616797e-02, 5.43544250e-02],\n",
       "       [1.81029230e-03, 7.35286550e-01, 2.62903158e-01],\n",
       "       [1.17850838e-02, 9.54698970e-01, 3.35159461e-02],\n",
       "       [1.07622919e-03, 9.85949574e-01, 1.29741968e-02],\n",
       "       [9.30417430e-01, 7.83437031e-03, 6.17481992e-02],\n",
       "       [8.28380464e-01, 4.71862355e-02, 1.24433300e-01],\n",
       "       [1.04909500e-02, 9.73347895e-01, 1.61611552e-02],\n",
       "       [8.60948043e-01, 5.55303708e-02, 8.35215860e-02],\n",
       "       [1.33412255e-01, 6.50594390e-01, 2.15993355e-01],\n",
       "       [7.30765304e-01, 1.05656400e-01, 1.63578296e-01],\n",
       "       [1.16618654e-03, 9.42358523e-01, 5.64752902e-02],\n",
       "       [8.97387412e-01, 1.55680588e-02, 8.70445289e-02],\n",
       "       [1.62490357e-03, 9.88954584e-01, 9.42051268e-03],\n",
       "       [3.98400114e-04, 9.87321266e-01, 1.22803343e-02],\n",
       "       [7.74532199e-01, 8.33017539e-02, 1.42166047e-01],\n",
       "       [8.84115663e-01, 6.51348000e-02, 5.07495372e-02],\n",
       "       [4.15974845e-02, 9.44961307e-01, 1.34412085e-02],\n",
       "       [6.01707987e-03, 2.30524689e-01, 7.63458231e-01]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpc.fit(train_X, train_y)\n",
    "gpc.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48648649 0.55405405 0.91891892 0.90410959 0.68493151 0.75\n",
      " 1.         0.98611111 0.95774648 1.        ]\n",
      "0.8242358145334222\n"
     ]
    }
   ],
   "source": [
    "print(crs_val)\n",
    "print(np.mean(crs_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "warm_start=FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.89312977, 0.91603053, 0.9389313 , 0.89312977, 0.9379845 ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_X_com = np.concatenate((test_X[:, 1:3], test_X[:, 4].reshape(-1,1)), axis=1)\n",
    "# 这个需要改为对应的特征\n",
    "\n",
    "gpc_score = round(gpc.score(test_X_com, test_y) * 100, 2)\n",
    "print(gpc_score)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(gpc, X_new, train_y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面为了方便把决策树的复制过来运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = np.concatenate((train[:, 1:3], train[:, 4].reshape(-1,1)), axis=1)\n",
    "test_X_com = np.concatenate((test_X[:, 1:3], test_X[:, 4].reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=10,min_samples_leaf=24)\n",
    "crs_val = cross_validate(tree_clf, train_new, target, cv=10, n_jobs=-1)\n",
    "# tree_clf.fit(train_new, target)\n",
    "# crs_val = [round(i.test_score*100, 2) for i in cross_validate(tree_clf, train_new, target, cv=10, n_jobs=-1)]\n",
    "# print(crs_val)\n",
    "# print(np.mean(crs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8134625195328455\n"
     ]
    }
   ],
   "source": [
    "print(crs_val['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.78\n"
     ]
    }
   ],
   "source": [
    "test_X_com = np.concatenate((test_X[:, 1:3], test_X[:, 4].reshape(-1,1)), axis=1)\n",
    "tree_clf_score = round(tree_clf.score(test_X_com, test_y) * 100, 2)\n",
    "print(tree_clf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id)\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=image_path(\"fix_param_tree.dot\"),\n",
    "        feature_names=['ta', 'max_minus_min', 'mean_minus_ta'],\n",
    "#         feature_names=features.columns[model.get_support(indices=True)],\n",
    "        class_names=list(str(i) for i in set(target_column.values)),\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x15c29ac8 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-3e078f23ea45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     11\u001b[0m \u001b[0msearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameter (CV score=%0.3f):\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;31m# we empty it and Python list are not thread-safe by default hence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m             \u001b[1;31m# the use of the lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x11437240 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x11437438 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x15d41ac8 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x12224ac8 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x15d41780 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x12918320 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x12918e80 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "param_grid = {\n",
    "    'max_depth':np.arange(1,30, 1),\n",
    "    'max_features':np.arange(1, 4, 1),\n",
    "    'max_leaf_nodes':np.arange(2, 30, 1),\n",
    "    'min_samples_leaf':np.arange(1, 20, 1),\n",
    "}\n",
    "search = GridSearchCV(tree_clf, param_grid, iid=False, cv=4, n_jobs=-1)\n",
    "search.fit(X_new, train_y)\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=3, max_leaf_nodes=10, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5, max_features=3, max_leaf_nodes=10, min_samples_leaf=1)\n",
    "tree_clf.fit(X_new, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cv方法在validation集上看参数变化对结果有没有优化作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_val = DecisionTreeClassifier()\n",
    "param_range = np.arange(3, 31)\n",
    "train_scores, test_scores = validation_curve(tree_val, train_new, target, n_jobs=-1, param_name='max_depth', param_range=param_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with DT\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "# plt.xlim(3,30)\n",
    "# plt.ylim(0.8, 1.1)\n",
    "lw = 2\n",
    "# plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "#              color=\"darkorange\", lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "# plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "#              color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "# plt.xlim(3,30)\n",
    "my_x_ticks = np.arange(3, 31, 1)\n",
    "plt.xticks(my_x_ticks)\n",
    "plt.plot(my_x_ticks, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\")\n",
    "plt.plot(my_x_ticks, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('I:\\graduation\\论文\\images\\max_depth', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对训练结果提高不大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = np.arange(100, 6, -1)\n",
    "train_scores, test_scores = validation_curve(tree_val, train_new, target, n_jobs=-1, param_name='min_samples_leaf', param_range=param_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with DT\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "my_x_ticks = np.arange(100,6,-5)\n",
    "plt.xticks(my_x_ticks)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('I:\\graduation\\论文\\images\\min_samples_leaf', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常的图是随着叶子结点的样本树越少，得分提高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = np.arange(50, 5, -1)\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "train_scores, test_scores = validation_curve(tree_val, X_new, train_y, n_jobs=-1, param_name='max_leaf_nodes', param_range=param_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with DT\")\n",
    "plt.xlabel(\"max_leaf_nodes\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.8, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对训练结果提高不大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.52"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_com = np.concatenate((test_X[:, 1:3], test_X[:, 4].reshape(-1, 1)), axis=1)\n",
    "pred_X = tree_clf.predict(test_X_com)\n",
    "acc_decision_tree = round(tree_clf.score(test_X_com, test_y) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89552239, 0.82089552, 0.89552239, 0.86567164, 0.87692308,\n",
       "       0.9375    , 0.90625   , 0.921875  , 0.9375    , 0.921875  ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(tree_clf, X_new, train_y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "def image_path(fig_id):\n",
    "    return os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id)\n",
    "\n",
    "dot_data = export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file=image_path(\"best_param_tree_featureImprv.dot\"),\n",
    "        feature_names=['ta', 'max_minus_min', 'mean_minus_ta'],\n",
    "#         feature_names=features.columns[model.get_support(indices=True)],\n",
    "        class_names=list(str(i) for i in set(target_column.values)),\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skewness</th>\n",
       "      <th>ta</th>\n",
       "      <th>max_minus_min</th>\n",
       "      <th>mode_minus_ta</th>\n",
       "      <th>mean_minus_ta</th>\n",
       "      <th>min_minus_ta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.481627</td>\n",
       "      <td>-1.648398</td>\n",
       "      <td>1.893270</td>\n",
       "      <td>2.197925</td>\n",
       "      <td>2.613718</td>\n",
       "      <td>-0.013848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.020538</td>\n",
       "      <td>-2.069276</td>\n",
       "      <td>2.204962</td>\n",
       "      <td>2.826934</td>\n",
       "      <td>3.236502</td>\n",
       "      <td>0.288823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.619943</td>\n",
       "      <td>-2.152305</td>\n",
       "      <td>2.090452</td>\n",
       "      <td>2.606653</td>\n",
       "      <td>3.349563</td>\n",
       "      <td>0.641610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.810879</td>\n",
       "      <td>-1.806920</td>\n",
       "      <td>2.069478</td>\n",
       "      <td>2.090469</td>\n",
       "      <td>2.745395</td>\n",
       "      <td>0.282838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.958884</td>\n",
       "      <td>-2.056055</td>\n",
       "      <td>1.831950</td>\n",
       "      <td>2.807175</td>\n",
       "      <td>2.778143</td>\n",
       "      <td>0.363366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.428125</td>\n",
       "      <td>-2.287192</td>\n",
       "      <td>1.863932</td>\n",
       "      <td>3.152612</td>\n",
       "      <td>3.273076</td>\n",
       "      <td>1.042830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.366167</td>\n",
       "      <td>-2.275435</td>\n",
       "      <td>2.412928</td>\n",
       "      <td>2.790673</td>\n",
       "      <td>3.524414</td>\n",
       "      <td>0.500719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.361242</td>\n",
       "      <td>-2.042016</td>\n",
       "      <td>2.237043</td>\n",
       "      <td>3.130563</td>\n",
       "      <td>3.206131</td>\n",
       "      <td>-0.101805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.444361</td>\n",
       "      <td>-1.922262</td>\n",
       "      <td>2.251973</td>\n",
       "      <td>2.951589</td>\n",
       "      <td>2.986991</td>\n",
       "      <td>-0.228650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.895882</td>\n",
       "      <td>-1.759358</td>\n",
       "      <td>2.261093</td>\n",
       "      <td>2.363757</td>\n",
       "      <td>2.962219</td>\n",
       "      <td>-0.256786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.896646</td>\n",
       "      <td>-1.918815</td>\n",
       "      <td>2.112514</td>\n",
       "      <td>2.602068</td>\n",
       "      <td>3.020415</td>\n",
       "      <td>-0.063082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-3.320586</td>\n",
       "      <td>-1.948248</td>\n",
       "      <td>1.904531</td>\n",
       "      <td>2.990426</td>\n",
       "      <td>3.150468</td>\n",
       "      <td>0.282419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-3.108458</td>\n",
       "      <td>-2.362353</td>\n",
       "      <td>2.529201</td>\n",
       "      <td>2.920573</td>\n",
       "      <td>3.499610</td>\n",
       "      <td>0.332167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-3.599037</td>\n",
       "      <td>-2.199110</td>\n",
       "      <td>1.972929</td>\n",
       "      <td>2.676604</td>\n",
       "      <td>3.596638</td>\n",
       "      <td>0.770604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.913126</td>\n",
       "      <td>-2.351360</td>\n",
       "      <td>2.098052</td>\n",
       "      <td>3.592882</td>\n",
       "      <td>3.600315</td>\n",
       "      <td>1.253828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.596562</td>\n",
       "      <td>-2.611853</td>\n",
       "      <td>2.283434</td>\n",
       "      <td>2.949084</td>\n",
       "      <td>3.507764</td>\n",
       "      <td>1.182542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.862855</td>\n",
       "      <td>-2.535360</td>\n",
       "      <td>2.149083</td>\n",
       "      <td>2.834764</td>\n",
       "      <td>3.477999</td>\n",
       "      <td>1.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.657059</td>\n",
       "      <td>-2.772756</td>\n",
       "      <td>2.234111</td>\n",
       "      <td>3.533926</td>\n",
       "      <td>3.640366</td>\n",
       "      <td>1.069796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.949850</td>\n",
       "      <td>-2.623949</td>\n",
       "      <td>2.114034</td>\n",
       "      <td>3.311532</td>\n",
       "      <td>3.518099</td>\n",
       "      <td>1.168750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.607001</td>\n",
       "      <td>-2.715425</td>\n",
       "      <td>1.946820</td>\n",
       "      <td>3.792613</td>\n",
       "      <td>3.544334</td>\n",
       "      <td>1.233156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.613852</td>\n",
       "      <td>-2.643499</td>\n",
       "      <td>2.115869</td>\n",
       "      <td>3.685119</td>\n",
       "      <td>3.510708</td>\n",
       "      <td>1.244155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-2.502400</td>\n",
       "      <td>-2.463098</td>\n",
       "      <td>2.140152</td>\n",
       "      <td>3.071137</td>\n",
       "      <td>3.298978</td>\n",
       "      <td>0.592742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.829863</td>\n",
       "      <td>-2.493508</td>\n",
       "      <td>2.081854</td>\n",
       "      <td>3.116586</td>\n",
       "      <td>3.160339</td>\n",
       "      <td>0.668270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.718305</td>\n",
       "      <td>-2.259113</td>\n",
       "      <td>2.140053</td>\n",
       "      <td>3.110648</td>\n",
       "      <td>3.105070</td>\n",
       "      <td>0.851465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-2.531053</td>\n",
       "      <td>-2.368757</td>\n",
       "      <td>2.359378</td>\n",
       "      <td>2.585774</td>\n",
       "      <td>3.164863</td>\n",
       "      <td>0.687890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.131266</td>\n",
       "      <td>-2.520722</td>\n",
       "      <td>2.314040</td>\n",
       "      <td>3.157257</td>\n",
       "      <td>3.136290</td>\n",
       "      <td>0.478781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-2.598307</td>\n",
       "      <td>-2.499743</td>\n",
       "      <td>2.289172</td>\n",
       "      <td>2.781534</td>\n",
       "      <td>3.194471</td>\n",
       "      <td>0.337387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-2.226334</td>\n",
       "      <td>-2.621693</td>\n",
       "      <td>2.452015</td>\n",
       "      <td>2.275051</td>\n",
       "      <td>3.129507</td>\n",
       "      <td>0.464105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.633027</td>\n",
       "      <td>-2.603726</td>\n",
       "      <td>2.457915</td>\n",
       "      <td>2.592568</td>\n",
       "      <td>3.113495</td>\n",
       "      <td>0.416422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.116034</td>\n",
       "      <td>-2.619682</td>\n",
       "      <td>2.292266</td>\n",
       "      <td>2.960786</td>\n",
       "      <td>3.246692</td>\n",
       "      <td>0.606490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0.050461</td>\n",
       "      <td>-0.844571</td>\n",
       "      <td>0.774935</td>\n",
       "      <td>0.652225</td>\n",
       "      <td>0.153940</td>\n",
       "      <td>-0.673173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.036260</td>\n",
       "      <td>-0.713467</td>\n",
       "      <td>0.708272</td>\n",
       "      <td>0.456288</td>\n",
       "      <td>0.154649</td>\n",
       "      <td>-0.540615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>-0.008655</td>\n",
       "      <td>-0.631516</td>\n",
       "      <td>0.661495</td>\n",
       "      <td>0.678180</td>\n",
       "      <td>0.088272</td>\n",
       "      <td>-0.728098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>-0.282678</td>\n",
       "      <td>-0.705852</td>\n",
       "      <td>1.052810</td>\n",
       "      <td>0.444907</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>-1.222515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.197903</td>\n",
       "      <td>-0.759977</td>\n",
       "      <td>0.746254</td>\n",
       "      <td>0.181429</td>\n",
       "      <td>0.184538</td>\n",
       "      <td>-0.363665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>-0.027549</td>\n",
       "      <td>-0.853800</td>\n",
       "      <td>1.361408</td>\n",
       "      <td>0.666018</td>\n",
       "      <td>0.152676</td>\n",
       "      <td>-1.170932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>0.288482</td>\n",
       "      <td>-0.750449</td>\n",
       "      <td>0.460509</td>\n",
       "      <td>0.511558</td>\n",
       "      <td>0.165836</td>\n",
       "      <td>-0.138576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0.170749</td>\n",
       "      <td>-0.833004</td>\n",
       "      <td>1.052810</td>\n",
       "      <td>0.290569</td>\n",
       "      <td>0.148429</td>\n",
       "      <td>-0.989515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>0.220163</td>\n",
       "      <td>-0.686553</td>\n",
       "      <td>0.389448</td>\n",
       "      <td>0.071695</td>\n",
       "      <td>0.139903</td>\n",
       "      <td>-0.150097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0.194309</td>\n",
       "      <td>-0.528563</td>\n",
       "      <td>0.493058</td>\n",
       "      <td>0.524315</td>\n",
       "      <td>0.114868</td>\n",
       "      <td>-0.342878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.193000</td>\n",
       "      <td>-0.653559</td>\n",
       "      <td>0.323892</td>\n",
       "      <td>0.366755</td>\n",
       "      <td>0.146840</td>\n",
       "      <td>-0.094241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>-0.078289</td>\n",
       "      <td>-0.805433</td>\n",
       "      <td>0.761237</td>\n",
       "      <td>0.593732</td>\n",
       "      <td>0.119325</td>\n",
       "      <td>-1.056225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.353477</td>\n",
       "      <td>-0.595946</td>\n",
       "      <td>0.501953</td>\n",
       "      <td>0.280652</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>-0.392930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.286568</td>\n",
       "      <td>-0.643505</td>\n",
       "      <td>0.155724</td>\n",
       "      <td>0.351728</td>\n",
       "      <td>0.141382</td>\n",
       "      <td>-0.070544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.228782</td>\n",
       "      <td>-0.648221</td>\n",
       "      <td>0.110251</td>\n",
       "      <td>0.358777</td>\n",
       "      <td>0.131996</td>\n",
       "      <td>-0.097483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.109471</td>\n",
       "      <td>-0.685471</td>\n",
       "      <td>0.796260</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.121741</td>\n",
       "      <td>-0.737674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.026183</td>\n",
       "      <td>-0.600849</td>\n",
       "      <td>0.306723</td>\n",
       "      <td>0.287979</td>\n",
       "      <td>0.115001</td>\n",
       "      <td>-0.081738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0.218538</td>\n",
       "      <td>-0.861294</td>\n",
       "      <td>0.115351</td>\n",
       "      <td>0.332848</td>\n",
       "      <td>0.260472</td>\n",
       "      <td>0.476929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>0.356018</td>\n",
       "      <td>-0.809715</td>\n",
       "      <td>0.679447</td>\n",
       "      <td>-0.777347</td>\n",
       "      <td>0.194105</td>\n",
       "      <td>-0.400451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>0.357978</td>\n",
       "      <td>-0.789368</td>\n",
       "      <td>0.382721</td>\n",
       "      <td>-0.119016</td>\n",
       "      <td>0.195947</td>\n",
       "      <td>-0.020743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>-0.235311</td>\n",
       "      <td>-0.867219</td>\n",
       "      <td>0.947609</td>\n",
       "      <td>0.341703</td>\n",
       "      <td>0.161047</td>\n",
       "      <td>-0.807139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>-0.352008</td>\n",
       "      <td>-0.720955</td>\n",
       "      <td>0.620159</td>\n",
       "      <td>0.467479</td>\n",
       "      <td>0.109564</td>\n",
       "      <td>-0.664068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.088403</td>\n",
       "      <td>-0.741925</td>\n",
       "      <td>0.679861</td>\n",
       "      <td>0.498819</td>\n",
       "      <td>0.130213</td>\n",
       "      <td>-0.474502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.254359</td>\n",
       "      <td>-0.744311</td>\n",
       "      <td>0.523035</td>\n",
       "      <td>0.158016</td>\n",
       "      <td>0.182573</td>\n",
       "      <td>-0.185139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.394348</td>\n",
       "      <td>-0.571174</td>\n",
       "      <td>0.158333</td>\n",
       "      <td>-0.445110</td>\n",
       "      <td>0.129212</td>\n",
       "      <td>0.200300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.070015</td>\n",
       "      <td>-0.498176</td>\n",
       "      <td>0.239610</td>\n",
       "      <td>0.478902</td>\n",
       "      <td>0.058826</td>\n",
       "      <td>-0.344529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>-0.652282</td>\n",
       "      <td>-0.549023</td>\n",
       "      <td>1.262044</td>\n",
       "      <td>0.899264</td>\n",
       "      <td>-0.123470</td>\n",
       "      <td>-1.882949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.214645</td>\n",
       "      <td>-0.492505</td>\n",
       "      <td>0.680904</td>\n",
       "      <td>0.470426</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>-0.813860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.301669</td>\n",
       "      <td>-0.569637</td>\n",
       "      <td>0.508446</td>\n",
       "      <td>0.241331</td>\n",
       "      <td>0.039620</td>\n",
       "      <td>-0.377092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>-0.032773</td>\n",
       "      <td>-0.676342</td>\n",
       "      <td>0.811909</td>\n",
       "      <td>0.400804</td>\n",
       "      <td>0.067548</td>\n",
       "      <td>-1.091303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>726 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     skewness        ta  max_minus_min  mode_minus_ta  mean_minus_ta  \\\n",
       "0   -2.481627 -1.648398       1.893270       2.197925       2.613718   \n",
       "1   -3.020538 -2.069276       2.204962       2.826934       3.236502   \n",
       "2   -2.619943 -2.152305       2.090452       2.606653       3.349563   \n",
       "3   -1.810879 -1.806920       2.069478       2.090469       2.745395   \n",
       "4   -1.958884 -2.056055       1.831950       2.807175       2.778143   \n",
       "5   -1.428125 -2.287192       1.863932       3.152612       3.273076   \n",
       "6   -2.366167 -2.275435       2.412928       2.790673       3.524414   \n",
       "7   -3.361242 -2.042016       2.237043       3.130563       3.206131   \n",
       "8   -3.444361 -1.922262       2.251973       2.951589       2.986991   \n",
       "9   -2.895882 -1.759358       2.261093       2.363757       2.962219   \n",
       "10  -2.896646 -1.918815       2.112514       2.602068       3.020415   \n",
       "11  -3.320586 -1.948248       1.904531       2.990426       3.150468   \n",
       "12  -3.108458 -2.362353       2.529201       2.920573       3.499610   \n",
       "13  -3.599037 -2.199110       1.972929       2.676604       3.596638   \n",
       "14  -1.913126 -2.351360       2.098052       3.592882       3.600315   \n",
       "15  -1.596562 -2.611853       2.283434       2.949084       3.507764   \n",
       "16  -1.862855 -2.535360       2.149083       2.834764       3.477999   \n",
       "17  -1.657059 -2.772756       2.234111       3.533926       3.640366   \n",
       "18  -1.949850 -2.623949       2.114034       3.311532       3.518099   \n",
       "19  -1.607001 -2.715425       1.946820       3.792613       3.544334   \n",
       "20  -1.613852 -2.643499       2.115869       3.685119       3.510708   \n",
       "21  -2.502400 -2.463098       2.140152       3.071137       3.298978   \n",
       "22  -1.829863 -2.493508       2.081854       3.116586       3.160339   \n",
       "23  -1.718305 -2.259113       2.140053       3.110648       3.105070   \n",
       "24  -2.531053 -2.368757       2.359378       2.585774       3.164863   \n",
       "25  -2.131266 -2.520722       2.314040       3.157257       3.136290   \n",
       "26  -2.598307 -2.499743       2.289172       2.781534       3.194471   \n",
       "27  -2.226334 -2.621693       2.452015       2.275051       3.129507   \n",
       "28  -1.633027 -2.603726       2.457915       2.592568       3.113495   \n",
       "29  -2.116034 -2.619682       2.292266       2.960786       3.246692   \n",
       "..        ...       ...            ...            ...            ...   \n",
       "696  0.050461 -0.844571       0.774935       0.652225       0.153940   \n",
       "697  0.036260 -0.713467       0.708272       0.456288       0.154649   \n",
       "698 -0.008655 -0.631516       0.661495       0.678180       0.088272   \n",
       "699 -0.282678 -0.705852       1.052810       0.444907       0.104330   \n",
       "700  0.197903 -0.759977       0.746254       0.181429       0.184538   \n",
       "701 -0.027549 -0.853800       1.361408       0.666018       0.152676   \n",
       "702  0.288482 -0.750449       0.460509       0.511558       0.165836   \n",
       "703  0.170749 -0.833004       1.052810       0.290569       0.148429   \n",
       "704  0.220163 -0.686553       0.389448       0.071695       0.139903   \n",
       "705  0.194309 -0.528563       0.493058       0.524315       0.114868   \n",
       "706  0.193000 -0.653559       0.323892       0.366755       0.146840   \n",
       "707 -0.078289 -0.805433       0.761237       0.593732       0.119325   \n",
       "708  0.353477 -0.595946       0.501953       0.280652       0.036767   \n",
       "709  0.286568 -0.643505       0.155724       0.351728       0.141382   \n",
       "710  0.228782 -0.648221       0.110251       0.358777       0.131996   \n",
       "711  0.109471 -0.685471       0.796260       0.070078       0.121741   \n",
       "712  0.026183 -0.600849       0.306723       0.287979       0.115001   \n",
       "713  0.218538 -0.861294       0.115351       0.332848       0.260472   \n",
       "714  0.356018 -0.809715       0.679447      -0.777347       0.194105   \n",
       "715  0.357978 -0.789368       0.382721      -0.119016       0.195947   \n",
       "716 -0.235311 -0.867219       0.947609       0.341703       0.161047   \n",
       "717 -0.352008 -0.720955       0.620159       0.467479       0.109564   \n",
       "718  0.088403 -0.741925       0.679861       0.498819       0.130213   \n",
       "719  0.254359 -0.744311       0.523035       0.158016       0.182573   \n",
       "720  0.394348 -0.571174       0.158333      -0.445110       0.129212   \n",
       "721  0.070015 -0.498176       0.239610       0.478902       0.058826   \n",
       "722 -0.652282 -0.549023       1.262044       0.899264      -0.123470   \n",
       "723  0.214645 -0.492505       0.680904       0.470426       0.026372   \n",
       "724  0.301669 -0.569637       0.508446       0.241331       0.039620   \n",
       "725 -0.032773 -0.676342       0.811909       0.400804       0.067548   \n",
       "\n",
       "     min_minus_ta  \n",
       "0       -0.013848  \n",
       "1        0.288823  \n",
       "2        0.641610  \n",
       "3        0.282838  \n",
       "4        0.363366  \n",
       "5        1.042830  \n",
       "6        0.500719  \n",
       "7       -0.101805  \n",
       "8       -0.228650  \n",
       "9       -0.256786  \n",
       "10      -0.063082  \n",
       "11       0.282419  \n",
       "12       0.332167  \n",
       "13       0.770604  \n",
       "14       1.253828  \n",
       "15       1.182542  \n",
       "16       1.001753  \n",
       "17       1.069796  \n",
       "18       1.168750  \n",
       "19       1.233156  \n",
       "20       1.244155  \n",
       "21       0.592742  \n",
       "22       0.668270  \n",
       "23       0.851465  \n",
       "24       0.687890  \n",
       "25       0.478781  \n",
       "26       0.337387  \n",
       "27       0.464105  \n",
       "28       0.416422  \n",
       "29       0.606490  \n",
       "..            ...  \n",
       "696     -0.673173  \n",
       "697     -0.540615  \n",
       "698     -0.728098  \n",
       "699     -1.222515  \n",
       "700     -0.363665  \n",
       "701     -1.170932  \n",
       "702     -0.138576  \n",
       "703     -0.989515  \n",
       "704     -0.150097  \n",
       "705     -0.342878  \n",
       "706     -0.094241  \n",
       "707     -1.056225  \n",
       "708     -0.392930  \n",
       "709     -0.070544  \n",
       "710     -0.097483  \n",
       "711     -0.737674  \n",
       "712     -0.081738  \n",
       "713      0.476929  \n",
       "714     -0.400451  \n",
       "715     -0.020743  \n",
       "716     -0.807139  \n",
       "717     -0.664068  \n",
       "718     -0.474502  \n",
       "719     -0.185139  \n",
       "720      0.200300  \n",
       "721     -0.344529  \n",
       "722     -1.882949  \n",
       "723     -0.813860  \n",
       "724     -0.377092  \n",
       "725     -1.091303  \n",
       "\n",
       "[726 rows x 6 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features_scaler, columns=features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同分类器比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58306683, -0.79773491],\n",
       "       [ 1.24369886, -0.77944135],\n",
       "       [ 0.70530663, -1.13458273],\n",
       "       ...,\n",
       "       [-0.49215812,  0.2941942 ],\n",
       "       [-0.33066043, -0.61017651],\n",
       "       [-0.58612012,  1.14127388]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = np.concatenate((train_X[:, 1:3], train_X[:, 4].reshape(-1,1)), axis=1)\n",
    "test_X_com = np.concatenate((test_X[:, 1:3], test_X[:, 4].reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "           weights='uniform') \n",
      " [0.88461538 0.91666667 0.86956522] \n",
      "\n",
      "SVC(C=0.025, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False) \n",
      " [0.53846154 0.58333333 0.56521739] \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      " [0.92307692 0.91666667 0.91304348] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessClassifier(copy_X_train=True,\n",
      "             kernel=1**2 * RBF(length_scale=1), max_iter_predict=100,\n",
      "             multi_class='one_vs_rest', n_jobs=None,\n",
      "             n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
      "             random_state=None, warm_start=False) \n",
      " [0.92307692 0.95833333 0.95652174] \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') \n",
      " [0.84615385 0.875      0.82608696] \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False) \n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92307692 0.91666667 0.86956522] \n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      " [0.92307692 0.91666667 0.95652174] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) \n",
      " [0.38461538 0.79166667 0.82608696] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=2000),\n",
    "    AdaBoostClassifier(),\n",
    "#     GaussianNB(),\n",
    "#     QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "for i in classifiers:\n",
    "    i.fit(train_new, train_y)\n",
    "    print(i, '\\n', cross_val_score(i, test_X_com, test_y), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma=2, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = np.concatenate([train_new, test_X_com], axis = 0)\n",
    "y_total = np.concatenate([train_y, test_y], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(726, 3)\n",
      "(726,)\n"
     ]
    }
   ],
   "source": [
    "print(X_total.shape)\n",
    "print(y_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, 2, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_total[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90540541, 0.85135135, 0.90540541, 0.91780822, 0.94520548,\n",
       "       0.97222222, 0.91666667, 0.90277778, 0.94366197, 0.95774648])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svc, X_total, y_total, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218250990000001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([0.90540541, 0.85135135, 0.90540541, 0.91780822, 0.94520548,\n",
    "       0.97222222, 0.91666667, 0.90277778, 0.94366197, 0.95774648])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=2, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'kernel': ('linear', 'rbf'), 'C': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':np.arange(1, 11)}\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 3, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "E:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02480149, 0.01340075, 0.01580091, 0.01360083, 0.019801  ,\n",
       "        0.01440072, 0.0248014 , 0.01180067, 0.02160125, 0.0120007 ,\n",
       "        0.02000122, 0.01180062, 0.0228013 , 0.0128006 , 0.02520142,\n",
       "        0.01240072, 0.02600145, 0.0152009 , 0.03040171, 0.01380081]),\n",
       " 'std_fit_time': array([0.01427513, 0.00101985, 0.0017205 , 0.00079995, 0.00213544,\n",
       "        0.00257695, 0.00541877, 0.00040014, 0.00332289, 0.00063249,\n",
       "        0.00063241, 0.00074842, 0.00074843, 0.00116629, 0.00278588,\n",
       "        0.00135659, 0.00209774, 0.0035442 , 0.00366617, 0.00074838]),\n",
       " 'mean_score_time': array([0.0026001 , 0.00220013, 0.00220008, 0.00300026, 0.00200009,\n",
       "        0.00280023, 0.00200005, 0.00200014, 0.00200009, 0.00220008,\n",
       "        0.00180006, 0.00220017, 0.00200009, 0.00160012, 0.00140014,\n",
       "        0.00180001, 0.00200009, 0.00200005, 0.00180011, 0.00160017]),\n",
       " 'std_score_time': array([8.00025479e-04, 4.00066404e-04, 3.99971008e-04, 1.50789149e-07,\n",
       "        0.00000000e+00, 4.00066404e-04, 6.32485089e-04, 9.53674316e-08,\n",
       "        0.00000000e+00, 3.99971008e-04, 4.00066376e-04, 4.00042545e-04,\n",
       "        0.00000000e+00, 4.90057117e-04, 4.89862441e-04, 4.00042545e-04,\n",
       "        6.32485100e-04, 9.53674316e-08, 4.00090228e-04, 4.89998722e-04]),\n",
       " 'param_C': masked_array(data=[1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'kernel': 'linear'},\n",
       "  {'C': 2, 'kernel': 'rbf'},\n",
       "  {'C': 3, 'kernel': 'linear'},\n",
       "  {'C': 3, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'kernel': 'linear'},\n",
       "  {'C': 4, 'kernel': 'rbf'},\n",
       "  {'C': 5, 'kernel': 'linear'},\n",
       "  {'C': 5, 'kernel': 'rbf'},\n",
       "  {'C': 6, 'kernel': 'linear'},\n",
       "  {'C': 6, 'kernel': 'rbf'},\n",
       "  {'C': 7, 'kernel': 'linear'},\n",
       "  {'C': 7, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'kernel': 'linear'},\n",
       "  {'C': 8, 'kernel': 'rbf'},\n",
       "  {'C': 9, 'kernel': 'linear'},\n",
       "  {'C': 9, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.79452055, 0.89726027, 0.79452055, 0.89041096, 0.80136986,\n",
       "        0.89726027, 0.80136986, 0.89726027, 0.80136986, 0.89726027,\n",
       "        0.80136986, 0.89726027, 0.80136986, 0.90410959, 0.80136986,\n",
       "        0.89726027, 0.80136986, 0.90410959, 0.80136986, 0.90410959]),\n",
       " 'split1_test_score': array([0.7739726 , 0.9109589 , 0.78767123, 0.9109589 , 0.78767123,\n",
       "        0.91780822, 0.79452055, 0.91780822, 0.78767123, 0.91780822,\n",
       "        0.78767123, 0.91780822, 0.78767123, 0.91780822, 0.78767123,\n",
       "        0.91780822, 0.78767123, 0.91780822, 0.78767123, 0.92465753]),\n",
       " 'split2_test_score': array([0.79452055, 0.95205479, 0.79452055, 0.95205479, 0.79452055,\n",
       "        0.95890411, 0.79452055, 0.94520548, 0.79452055, 0.94520548,\n",
       "        0.79452055, 0.94520548, 0.79452055, 0.93835616, 0.79452055,\n",
       "        0.94520548, 0.79452055, 0.93835616, 0.79452055, 0.93835616]),\n",
       " 'split3_test_score': array([0.79166667, 0.90972222, 0.78472222, 0.90972222, 0.78472222,\n",
       "        0.90972222, 0.78472222, 0.90972222, 0.78472222, 0.91666667,\n",
       "        0.78472222, 0.91666667, 0.78472222, 0.91666667, 0.78472222,\n",
       "        0.91666667, 0.78472222, 0.91666667, 0.78472222, 0.91666667]),\n",
       " 'split4_test_score': array([0.81944444, 0.95833333, 0.81944444, 0.95138889, 0.81944444,\n",
       "        0.95138889, 0.81944444, 0.95138889, 0.81944444, 0.95138889,\n",
       "        0.81944444, 0.95138889, 0.81944444, 0.95138889, 0.81944444,\n",
       "        0.95138889, 0.81944444, 0.95138889, 0.81944444, 0.95138889]),\n",
       " 'mean_test_score': array([0.79476584, 0.92561983, 0.79614325, 0.92286501, 0.79752066,\n",
       "        0.92699725, 0.79889807, 0.92424242, 0.79752066, 0.92561983,\n",
       "        0.79752066, 0.92561983, 0.79752066, 0.92561983, 0.79752066,\n",
       "        0.92561983, 0.79752066, 0.92561983, 0.79752066, 0.92699725]),\n",
       " 'std_test_score': array([0.01448025, 0.02465544, 0.0122089 , 0.0246436 , 0.01233386,\n",
       "        0.02401548, 0.01151207, 0.02076285, 0.01233386, 0.01996906,\n",
       "        0.01233386, 0.01996906, 0.01233386, 0.01689827, 0.01233386,\n",
       "        0.01996906, 0.01233386, 0.01689827, 0.01233386, 0.01647935]),\n",
       " 'rank_test_score': array([20,  3, 19, 10, 12,  1, 11,  9, 12,  3, 12,  3, 12,  3, 12,  3, 12,\n",
       "         3, 12,  1]),\n",
       " 'split0_train_score': array([0.79827586, 0.93275862, 0.80172414, 0.93275862, 0.81034483,\n",
       "        0.93275862, 0.81206897, 0.93448276, 0.81034483, 0.9362069 ,\n",
       "        0.81034483, 0.93793103, 0.81034483, 0.93965517, 0.81206897,\n",
       "        0.94137931, 0.81206897, 0.94310345, 0.81206897, 0.93965517]),\n",
       " 'split1_train_score': array([0.80862069, 0.92758621, 0.81896552, 0.9362069 , 0.81724138,\n",
       "        0.9362069 , 0.8137931 , 0.93965517, 0.8137931 , 0.94137931,\n",
       "        0.8137931 , 0.93793103, 0.8137931 , 0.93793103, 0.81206897,\n",
       "        0.93965517, 0.81206897, 0.93965517, 0.81206897, 0.94310345]),\n",
       " 'split2_train_score': array([0.78793103, 0.92413793, 0.78793103, 0.92586207, 0.78793103,\n",
       "        0.92241379, 0.78793103, 0.92758621, 0.78793103, 0.92931034,\n",
       "        0.78793103, 0.93103448, 0.78793103, 0.93103448, 0.78793103,\n",
       "        0.93103448, 0.78793103, 0.93103448, 0.78793103, 0.93275862]),\n",
       " 'split3_train_score': array([0.78350515, 0.93127148, 0.78522337, 0.92783505, 0.78350515,\n",
       "        0.93298969, 0.78694158, 0.93298969, 0.78694158, 0.93298969,\n",
       "        0.78694158, 0.93298969, 0.78694158, 0.93298969, 0.78694158,\n",
       "        0.93642612, 0.78694158, 0.93642612, 0.78694158, 0.93642612]),\n",
       " 'split4_train_score': array([0.79381443, 0.91580756, 0.79725086, 0.91752577, 0.79553265,\n",
       "        0.92268041, 0.79553265, 0.92611684, 0.79553265, 0.92611684,\n",
       "        0.79553265, 0.92611684, 0.79553265, 0.92783505, 0.79553265,\n",
       "        0.92955326, 0.79725086, 0.92955326, 0.79725086, 0.92955326]),\n",
       " 'mean_train_score': array([0.79442943, 0.92631236, 0.79821898, 0.92803768, 0.79891101,\n",
       "        0.92940988, 0.79925347, 0.93216613, 0.79890864, 0.93320062,\n",
       "        0.79890864, 0.93320062, 0.79890864, 0.93388909, 0.79890864,\n",
       "        0.93560967, 0.79925228, 0.9359545 , 0.79925228, 0.93629932]),\n",
       " 'std_train_score': array([0.00869637, 0.00604729, 0.01198641, 0.00639215, 0.01293096,\n",
       "        0.00573515, 0.01156946, 0.00489286, 0.01120223, 0.00531578,\n",
       "        0.01120223, 0.00446476, 0.01120223, 0.00436335, 0.01114903,\n",
       "        0.00464616, 0.01106584, 0.00510308, 0.01106584, 0.00480874])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "svc = SVC(gamma=2)\n",
    "param_range = np.arange(1, 40, 1)\n",
    "train_scores, test_scores = validation_curve(svc, X_total, y_total, n_jobs=-1, param_name='C', param_range=param_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "my_x_ticks = np.arange(1,40,2)\n",
    "plt.xticks(my_x_ticks)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "plt.legend(loc=\"best\")\n",
    "# plt.savefig('I:\\graduation\\论文\\images\\C', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94594595 0.87837838 0.93243243 0.93150685 0.93150685 0.94444444\n",
      " 0.93055556 0.91666667 0.94366197 0.95774648]\n",
      "0.9312845572757785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma=2,C=18)\n",
    "cros = cross_val_score(svc, X_total, y_total, cv=10)\n",
    "print(cros)\n",
    "print(cros.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "svc = SVC(C=18)\n",
    "param_range = np.arange(1, 40, 1)\n",
    "train_scores, test_scores = validation_curve(svc, X_total, y_total, n_jobs=-1, param_name='gamma', param_range=param_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"gamma\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "my_x_ticks = np.arange(1,40,2)\n",
    "plt.xticks(my_x_ticks)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig('I:\\graduation\\论文\\images\\gamma', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "svc = SVC(C=18,gamma=2)\n",
    "param_range = np.arange(1e-4, 1e-2, 1e-5)\n",
    "train_scores, test_scores = validation_curve(svc, X_total, y_total, n_jobs=-1, param_name='tol', param_range=param_range, cv=10, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(\"gamma\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "# my_x_ticks = np.arange(1,40,2)\n",
    "plt.xticks(my_x_ticks)\n",
    "plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\")\n",
    "plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "plt.legend(loc=\"best\")\n",
    "# plt.savefig('I:\\graduation\\论文\\images\\gamma', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94594595 0.87837838 0.93243243 0.93150685 0.93150685 0.94444444\n",
      " 0.93055556 0.91666667 0.94366197 0.95774648]\n",
      "0.9312845572757785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma=2, C=18)\n",
    "cros = cross_val_score(svc, X_total, y_total, cv=10)\n",
    "print(cros)\n",
    "print(cros.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
